{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to build a model to classify text, using the TREC-6 dataset.\n",
    "\n",
    "The TREC-6 dataset consist on a set of 5,952 questions written in English, classified in the following categories, depending on the answer:\n",
    "\n",
    "* HUM: Human\n",
    "* DESC: Description\n",
    "* ABBR: Abbreviation\n",
    "* LOC: Location\n",
    "* NUM: Number\n",
    "* ENTY: Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: spacy in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (1.3.1)\n",
      "Requirement already satisfied: numpy in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (1.17.4)\n",
      "Requirement already satisfied: tqdm in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (4.40.1)\n",
      "Requirement already satisfied: six in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (1.13.0)\n",
      "Requirement already satisfied: requests in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (2.22.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (0.0.8)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: setuptools in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (40.6.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (1.25.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (8.0.2)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.17.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.2)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: setuptools in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (40.6.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.40.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /Users/cenk.bircanoglu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (8.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the model via spacy.load('en_core_web_sm')\r\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\r\n",
      "/Users/cenk.bircanoglu/.pyenv/versions/learn-pytorch/lib/python3.6/site-packages/en_core_web_sm\r\n",
      "-->\r\n",
      "/Users/cenk.bircanoglu/.pyenv/versions/learn-pytorch/lib/python3.6/site-packages/spacy/data/en\r\n",
      "You can now load the model via spacy.load('en')\r\n"
     ]
    }
   ],
   "source": [
    "# The following lines will install the torchtext and spacy libraries, \n",
    "# used to prepare text datasets for models in PyTorch.\n",
    "\n",
    "!pip install torchtext spacy\n",
    "#!conda install -c conda-forge spacy -y\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 5452\n",
      "Test length: 500\n"
     ]
    }
   ],
   "source": [
    "# Get datasets\n",
    "text_field = data.Field(lower=True, batch_first=True, tokenize='spacy')\n",
    "label_field = data.Field(sequential=False, unk_token = None)\n",
    "train, test = datasets.TREC.splits(text_field, label_field)\n",
    "\n",
    "print('Train length:',str(len(train)))\n",
    "print('Test length:',str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how long does it take the typical american to eat 23 quarts of ice cream ? NUM\n",
      "saddam hussein was compared to whom by president bush ? HUM\n",
      "what is the homelite inc. home page ? LOC\n",
      "what was the first funk ' n lata , brazilian group , success ? DESC\n",
      "who is section manager for guidance and control systems at jpl ? HUM\n",
      "what does s.o.s. stand for ? ABBR\n",
      "what is splatterpunk ? DESC\n",
      "how many points are there on a backgammon board ? NUM\n",
      "how do cameras take pictures ? DESC\n",
      "who is samuel pickering ? HUM\n"
     ]
    }
   ],
   "source": [
    "# Show some examples\n",
    "\n",
    "for i in range(10):\n",
    "    random_index = random.randint(0,len(train))\n",
    "    print(' '.join(train.examples[random_index].text), train.examples[random_index].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 5002\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "vocab_length = 5000\n",
    "text_field.build_vocab(train, max_size=vocab_length)\n",
    "label_field.build_vocab(train)\n",
    "\n",
    "classes_count = len(label_field.vocab)\n",
    "word_count = len(text_field.vocab)\n",
    "print('Vocabulary length:', word_count)\n",
    "print('Number of classes:', classes_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x12ac260f0>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             '?': 2,\n",
       "             'the': 3,\n",
       "             'what': 4,\n",
       "             'is': 5,\n",
       "             'of': 6,\n",
       "             'in': 7,\n",
       "             'a': 8,\n",
       "             '`': 9,\n",
       "             'how': 10,\n",
       "             \"'s\": 11,\n",
       "             'was': 12,\n",
       "             'to': 13,\n",
       "             'who': 14,\n",
       "             ',': 15,\n",
       "             'are': 16,\n",
       "             'for': 17,\n",
       "             'and': 18,\n",
       "             \"''\": 19,\n",
       "             'does': 20,\n",
       "             'did': 21,\n",
       "             '-': 22,\n",
       "             'do': 23,\n",
       "             'many': 24,\n",
       "             'name': 25,\n",
       "             'on': 26,\n",
       "             'where': 27,\n",
       "             'i': 28,\n",
       "             'first': 29,\n",
       "             'you': 30,\n",
       "             'can': 31,\n",
       "             'when': 32,\n",
       "             'world': 33,\n",
       "             'from': 34,\n",
       "             'which': 35,\n",
       "             'by': 36,\n",
       "             'that': 37,\n",
       "             'u.s.': 38,\n",
       "             'country': 39,\n",
       "             'most': 40,\n",
       "             'an': 41,\n",
       "             'as': 42,\n",
       "             'with': 43,\n",
       "             'have': 44,\n",
       "             'city': 45,\n",
       "             '.': 46,\n",
       "             'has': 47,\n",
       "             'why': 48,\n",
       "             \"'\": 49,\n",
       "             'it': 50,\n",
       "             'there': 51,\n",
       "             'be': 52,\n",
       "             'people': 53,\n",
       "             'get': 54,\n",
       "             'at': 55,\n",
       "             'were': 56,\n",
       "             'find': 57,\n",
       "             'called': 58,\n",
       "             'his': 59,\n",
       "             'year': 60,\n",
       "             'state': 61,\n",
       "             'president': 62,\n",
       "             'american': 63,\n",
       "             'two': 64,\n",
       "             'largest': 65,\n",
       "             'mean': 66,\n",
       "             'war': 67,\n",
       "             'fear': 68,\n",
       "             'made': 69,\n",
       "             'new': 70,\n",
       "             'much': 71,\n",
       "             'long': 72,\n",
       "             'between': 73,\n",
       "             ':': 74,\n",
       "             'its': 75,\n",
       "             'origin': 76,\n",
       "             'used': 77,\n",
       "             'word': 78,\n",
       "             'about': 79,\n",
       "             'company': 80,\n",
       "             'known': 81,\n",
       "             'movie': 82,\n",
       "             'tv': 83,\n",
       "             'film': 84,\n",
       "             'kind': 85,\n",
       "             'one': 86,\n",
       "             'all': 87,\n",
       "             'famous': 88,\n",
       "             'best': 89,\n",
       "             'day': 90,\n",
       "             'or': 91,\n",
       "             'make': 92,\n",
       "             'take': 93,\n",
       "             'game': 94,\n",
       "             'he': 95,\n",
       "             'stand': 96,\n",
       "             'time': 97,\n",
       "             'up': 98,\n",
       "             'your': 99,\n",
       "             'live': 100,\n",
       "             'invented': 101,\n",
       "             'man': 102,\n",
       "             'book': 103,\n",
       "             'come': 104,\n",
       "             'only': 105,\n",
       "             'color': 106,\n",
       "             'john': 107,\n",
       "             'my': 108,\n",
       "             'not': 109,\n",
       "             'into': 110,\n",
       "             'old': 111,\n",
       "             'out': 112,\n",
       "             'play': 113,\n",
       "             'show': 114,\n",
       "             'term': 115,\n",
       "             'their': 116,\n",
       "             'wrote': 117,\n",
       "             'states': 118,\n",
       "             'countries': 119,\n",
       "             'last': 120,\n",
       "             'star': 121,\n",
       "             'america': 122,\n",
       "             'four': 123,\n",
       "             'home': 124,\n",
       "             'if': 125,\n",
       "             'named': 126,\n",
       "             'south': 127,\n",
       "             'won': 128,\n",
       "             'call': 129,\n",
       "             'highest': 130,\n",
       "             'team': 131,\n",
       "             'baseball': 132,\n",
       "             'character': 133,\n",
       "             'difference': 134,\n",
       "             'had': 135,\n",
       "             'king': 136,\n",
       "             'number': 137,\n",
       "             'river': 138,\n",
       "             'after': 139,\n",
       "             'english': 140,\n",
       "             'use': 141,\n",
       "             'born': 142,\n",
       "             'three': 143,\n",
       "             'died': 144,\n",
       "             'information': 145,\n",
       "             'novel': 146,\n",
       "             'played': 147,\n",
       "             'said': 148,\n",
       "             'some': 149,\n",
       "             'song': 150,\n",
       "             'work': 151,\n",
       "             'been': 152,\n",
       "             'black': 153,\n",
       "             'united': 154,\n",
       "             'actor': 155,\n",
       "             'average': 156,\n",
       "             'become': 157,\n",
       "             'capital': 158,\n",
       "             'college': 159,\n",
       "             'common': 160,\n",
       "             'dog': 161,\n",
       "             'say': 162,\n",
       "             'us': 163,\n",
       "             'will': 164,\n",
       "             'years': 165,\n",
       "             '1': 166,\n",
       "             'actress': 167,\n",
       "             'body': 168,\n",
       "             'computer': 169,\n",
       "             'earth': 170,\n",
       "             'go': 171,\n",
       "             'names': 172,\n",
       "             'population': 173,\n",
       "             'second': 174,\n",
       "             'water': 175,\n",
       "             'california': 176,\n",
       "             'drink': 177,\n",
       "             'food': 178,\n",
       "             'group': 179,\n",
       "             'located': 180,\n",
       "             'mountain': 181,\n",
       "             'sport': 182,\n",
       "             't': 183,\n",
       "             'they': 184,\n",
       "             'woman': 185,\n",
       "             'would': 186,\n",
       "             'die': 187,\n",
       "             'during': 188,\n",
       "             'good': 189,\n",
       "             'island': 190,\n",
       "             'like': 191,\n",
       "             'north': 192,\n",
       "             'space': 193,\n",
       "             'than': 194,\n",
       "             'times': 195,\n",
       "             'top': 196,\n",
       "             'york': 197,\n",
       "             'animal': 198,\n",
       "             'killed': 199,\n",
       "             'longest': 200,\n",
       "             'money': 201,\n",
       "             'school': 202,\n",
       "             'sea': 203,\n",
       "             'great': 204,\n",
       "             'history': 205,\n",
       "             'law': 206,\n",
       "             'more': 207,\n",
       "             'over': 208,\n",
       "             'part': 209,\n",
       "             'popular': 210,\n",
       "             'portrayed': 211,\n",
       "             'through': 212,\n",
       "             'university': 213,\n",
       "             'big': 214,\n",
       "             'different': 215,\n",
       "             'her': 216,\n",
       "             'language': 217,\n",
       "             'major': 218,\n",
       "             'makes': 219,\n",
       "             'person': 220,\n",
       "             'red': 221,\n",
       "             'should': 222,\n",
       "             'way': 223,\n",
       "             'car': 224,\n",
       "             'cities': 225,\n",
       "             'date': 226,\n",
       "             'each': 227,\n",
       "             'five': 228,\n",
       "             'general': 229,\n",
       "             'horse': 230,\n",
       "             'internet': 231,\n",
       "             'line': 232,\n",
       "             'meaning': 233,\n",
       "             'national': 234,\n",
       "             'title': 235,\n",
       "             'west': 236,\n",
       "             'address': 237,\n",
       "             'became': 238,\n",
       "             'charles': 239,\n",
       "             'contains': 240,\n",
       "             'cost': 241,\n",
       "             'craft': 242,\n",
       "             'created': 243,\n",
       "             'french': 244,\n",
       "             'international': 245,\n",
       "             'leader': 246,\n",
       "             'life': 247,\n",
       "             'miles': 248,\n",
       "             'russian': 249,\n",
       "             'so': 250,\n",
       "             'write': 251,\n",
       "             'battle': 252,\n",
       "             'biggest': 253,\n",
       "             'built': 254,\n",
       "             'causes': 255,\n",
       "             'letter': 256,\n",
       "             'me': 257,\n",
       "             'place': 258,\n",
       "             'randy': 259,\n",
       "             'white': 260,\n",
       "             'whose': 261,\n",
       "             'abbreviation': 262,\n",
       "             'airport': 263,\n",
       "             'bridge': 264,\n",
       "             'century': 265,\n",
       "             'features': 266,\n",
       "             'feet': 267,\n",
       "             'form': 268,\n",
       "             'found': 269,\n",
       "             'games': 270,\n",
       "             'ii': 271,\n",
       "             'little': 272,\n",
       "             'moon': 273,\n",
       "             'power': 274,\n",
       "             'queen': 275,\n",
       "             'seven': 276,\n",
       "             'system': 277,\n",
       "             '5': 278,\n",
       "             'air': 279,\n",
       "             'baby': 280,\n",
       "             'begin': 281,\n",
       "             'boasts': 282,\n",
       "             'british': 283,\n",
       "             'children': 284,\n",
       "             'colors': 285,\n",
       "             'comic': 286,\n",
       "             'death': 287,\n",
       "             'e': 288,\n",
       "             'eat': 289,\n",
       "             'england': 290,\n",
       "             'following': 291,\n",
       "             'george': 292,\n",
       "             'germany': 293,\n",
       "             'high': 294,\n",
       "             'human': 295,\n",
       "             'james': 296,\n",
       "             'kennedy': 297,\n",
       "             'league': 298,\n",
       "             'london': 299,\n",
       "             'love': 300,\n",
       "             'men': 301,\n",
       "             'nickname': 302,\n",
       "             'nixon': 303,\n",
       "             'no': 304,\n",
       "             'office': 305,\n",
       "             'park': 306,\n",
       "             'player': 307,\n",
       "             'san': 308,\n",
       "             'someone': 309,\n",
       "             'spanish': 310,\n",
       "             'type': 311,\n",
       "             '2': 312,\n",
       "             'area': 313,\n",
       "             'blood': 314,\n",
       "             'bowl': 315,\n",
       "             'disease': 316,\n",
       "             'european': 317,\n",
       "             'held': 318,\n",
       "             'hit': 319,\n",
       "             'hole': 320,\n",
       "             'house': 321,\n",
       "             'islands': 322,\n",
       "             'japanese': 323,\n",
       "             'letters': 324,\n",
       "             'may': 325,\n",
       "             'mother': 326,\n",
       "             'nn': 327,\n",
       "             'product': 328,\n",
       "             'rate': 329,\n",
       "             'real': 330,\n",
       "             'soft': 331,\n",
       "             'television': 332,\n",
       "             'washington': 333,\n",
       "             'animals': 334,\n",
       "             'before': 335,\n",
       "             'bill': 336,\n",
       "             'business': 337,\n",
       "             'center': 338,\n",
       "             'chemical': 339,\n",
       "             'father': 340,\n",
       "             'female': 341,\n",
       "             'happened': 342,\n",
       "             'know': 343,\n",
       "             'lawyer': 344,\n",
       "             'married': 345,\n",
       "             'member': 346,\n",
       "             'o': 347,\n",
       "             'ocean': 348,\n",
       "             'st.': 349,\n",
       "             'super': 350,\n",
       "             'william': 351,\n",
       "             'words': 352,\n",
       "             '&': 353,\n",
       "             'age': 354,\n",
       "             'building': 355,\n",
       "             'christmas': 356,\n",
       "             'definition': 357,\n",
       "             'ever': 358,\n",
       "             'hitler': 359,\n",
       "             'ice': 360,\n",
       "             'lives': 361,\n",
       "             'music': 362,\n",
       "             'newspaper': 363,\n",
       "             'once': 364,\n",
       "             'runs': 365,\n",
       "             'series': 366,\n",
       "             'served': 367,\n",
       "             'singing': 368,\n",
       "             'soldiers': 369,\n",
       "             'tree': 370,\n",
       "             'whom': 371,\n",
       "             'win': 372,\n",
       "             '$': 373,\n",
       "             'africa': 374,\n",
       "             'another': 375,\n",
       "             'around': 376,\n",
       "             'ball': 377,\n",
       "             'beer': 378,\n",
       "             'being': 379,\n",
       "             'birth': 380,\n",
       "             'boy': 381,\n",
       "             'canada': 382,\n",
       "             'civil': 383,\n",
       "             'cnn': 384,\n",
       "             'code': 385,\n",
       "             'county': 386,\n",
       "             'dick': 387,\n",
       "             'end': 388,\n",
       "             'f.': 389,\n",
       "             'far': 390,\n",
       "             'girl': 391,\n",
       "             'greek': 392,\n",
       "             'indians': 393,\n",
       "             'jack': 394,\n",
       "             'main': 395,\n",
       "             'minister': 396,\n",
       "             'mississippi': 397,\n",
       "             'night': 398,\n",
       "             'oldest': 399,\n",
       "             'original': 400,\n",
       "             'other': 401,\n",
       "             'prime': 402,\n",
       "             'prize': 403,\n",
       "             'radio': 404,\n",
       "             'rock': 405,\n",
       "             'ship': 406,\n",
       "             'singer': 407,\n",
       "             'six': 408,\n",
       "             'sports': 409,\n",
       "             'store': 410,\n",
       "             'tell': 411,\n",
       "             'them': 412,\n",
       "             'travel': 413,\n",
       "             'tuberculosis': 414,\n",
       "             'we': 415,\n",
       "             'web': 416,\n",
       "             '10': 417,\n",
       "             '3': 418,\n",
       "             'art': 419,\n",
       "             'back': 420,\n",
       "             'basketball': 421,\n",
       "             'bible': 422,\n",
       "             'board': 423,\n",
       "             'but': 424,\n",
       "             'card': 425,\n",
       "             'cartoon': 426,\n",
       "             'china': 427,\n",
       "             'claim': 428,\n",
       "             'cold': 429,\n",
       "             'comedian': 430,\n",
       "             'cross': 431,\n",
       "             'department': 432,\n",
       "             'down': 433,\n",
       "             'east': 434,\n",
       "             'fame': 435,\n",
       "             'famed': 436,\n",
       "             'fast': 437,\n",
       "             'flag': 438,\n",
       "             'football': 439,\n",
       "             'former': 440,\n",
       "             'founded': 441,\n",
       "             'god': 442,\n",
       "             'gold': 443,\n",
       "             'indian': 444,\n",
       "             'introduced': 445,\n",
       "             'kentucky': 446,\n",
       "             'lake': 447,\n",
       "             'marvel': 448,\n",
       "             'musical': 449,\n",
       "             'never': 450,\n",
       "             'now': 451,\n",
       "             'olympic': 452,\n",
       "             'originate': 453,\n",
       "             'percentage': 454,\n",
       "             'pope': 455,\n",
       "             'produce': 456,\n",
       "             'richard': 457,\n",
       "             'role': 458,\n",
       "             'saw': 459,\n",
       "             'see': 460,\n",
       "             'size': 461,\n",
       "             'son': 462,\n",
       "             'starred': 463,\n",
       "             'story': 464,\n",
       "             'tax': 465,\n",
       "             'then': 466,\n",
       "             'thing': 467,\n",
       "             'while': 468,\n",
       "             '1984': 469,\n",
       "             'americans': 470,\n",
       "             'appear': 471,\n",
       "             'author': 472,\n",
       "             'bear': 473,\n",
       "             'berlin': 474,\n",
       "             'blue': 475,\n",
       "             'brothers': 476,\n",
       "             'cards': 477,\n",
       "             'caused': 478,\n",
       "             'child': 479,\n",
       "             'chinese': 480,\n",
       "             'director': 481,\n",
       "             'dubbed': 482,\n",
       "             'europe': 483,\n",
       "             'every': 484,\n",
       "             'family': 485,\n",
       "             'fastest': 486,\n",
       "             'favorite': 487,\n",
       "             'fought': 488,\n",
       "             'full': 489,\n",
       "             'give': 490,\n",
       "             'golf': 491,\n",
       "             'hair': 492,\n",
       "             'head': 493,\n",
       "             'income': 494,\n",
       "             'japan': 495,\n",
       "             'latin': 496,\n",
       "             'list': 497,\n",
       "             'lived': 498,\n",
       "             'look': 499,\n",
       "             'los': 500,\n",
       "             'mile': 501,\n",
       "             'mount': 502,\n",
       "             'need': 503,\n",
       "             'organization': 504,\n",
       "             'own': 505,\n",
       "             'record': 506,\n",
       "             'shot': 507,\n",
       "             'sioux': 508,\n",
       "             'sometimes': 509,\n",
       "             'soviet': 510,\n",
       "             'species': 511,\n",
       "             'start': 512,\n",
       "             'started': 513,\n",
       "             'steven': 514,\n",
       "             'street': 515,\n",
       "             'strip': 516,\n",
       "             'symbol': 517,\n",
       "             'texas': 518,\n",
       "             'tom': 519,\n",
       "             'under': 520,\n",
       "             'vietnam': 521,\n",
       "             'website': 522,\n",
       "             'went': 523,\n",
       "             'wine': 524,\n",
       "             'women': 525,\n",
       "             'worth': 526,\n",
       "             '6': 527,\n",
       "             '8': 528,\n",
       "             'african': 529,\n",
       "             'angeles': 530,\n",
       "             'asian': 531,\n",
       "             'australia': 532,\n",
       "             'band': 533,\n",
       "             'beach': 534,\n",
       "             'because': 535,\n",
       "             'believe': 536,\n",
       "             'birds': 537,\n",
       "             'boxing': 538,\n",
       "             'brand': 539,\n",
       "             'captain': 540,\n",
       "             'characters': 541,\n",
       "             'chicago': 542,\n",
       "             'continent': 543,\n",
       "             'court': 544,\n",
       "             'days': 545,\n",
       "             'de': 546,\n",
       "             'desert': 547,\n",
       "             'eggs': 548,\n",
       "             'el': 549,\n",
       "             'eyes': 550,\n",
       "             'fire': 551,\n",
       "             'flight': 552,\n",
       "             'fly': 553,\n",
       "             'france': 554,\n",
       "             'gas': 555,\n",
       "             'gould': 556,\n",
       "             'government': 557,\n",
       "             'greatest': 558,\n",
       "             'green': 559,\n",
       "             'hand': 560,\n",
       "             'hands': 561,\n",
       "             'henry': 562,\n",
       "             'instrument': 563,\n",
       "             'jackson': 564,\n",
       "             'jaws': 565,\n",
       "             'languages': 566,\n",
       "             'left': 567,\n",
       "             'light': 568,\n",
       "             'lost': 569,\n",
       "             'magazine': 570,\n",
       "             'mail': 571,\n",
       "             'march': 572,\n",
       "             'massachusetts': 573,\n",
       "             'middle': 574,\n",
       "             'million': 575,\n",
       "             'monopoly': 576,\n",
       "             'months': 577,\n",
       "             'nuclear': 578,\n",
       "             'often': 579,\n",
       "             'oil': 580,\n",
       "             'paper': 581,\n",
       "             'peter': 582,\n",
       "             'plant': 583,\n",
       "             'plays': 584,\n",
       "             'point': 585,\n",
       "             'presidents': 586,\n",
       "             'prince': 587,\n",
       "             'produced': 588,\n",
       "             'rights': 589,\n",
       "             'run': 590,\n",
       "             'shea': 591,\n",
       "             'square': 592,\n",
       "             'stop': 593,\n",
       "             'sun': 594,\n",
       "             'tennis': 595,\n",
       "             'thatcher': 596,\n",
       "             'types': 597,\n",
       "             'wall': 598,\n",
       "             'winter': 599,\n",
       "             'writer': 600,\n",
       "             'aids': 601,\n",
       "             'alaska': 602,\n",
       "             'allowed': 603,\n",
       "             'also': 604,\n",
       "             'artist': 605,\n",
       "             'assassinated': 606,\n",
       "             'balls': 607,\n",
       "             'bond': 608,\n",
       "             'brown': 609,\n",
       "             'build': 610,\n",
       "             'buried': 611,\n",
       "             'cars': 612,\n",
       "             'cat': 613,\n",
       "             'claimed': 614,\n",
       "             'comes': 615,\n",
       "             'companies': 616,\n",
       "             'considered': 617,\n",
       "             'cover': 618,\n",
       "             'cowboy': 619,\n",
       "             'current': 620,\n",
       "             'dead': 621,\n",
       "             'element': 622,\n",
       "             'empire': 623,\n",
       "             'eye': 624,\n",
       "             'face': 625,\n",
       "             'featured': 626,\n",
       "             'federal': 627,\n",
       "             'follow': 628,\n",
       "             'formed': 629,\n",
       "             'golden': 630,\n",
       "             'got': 631,\n",
       "             'headquarters': 632,\n",
       "             'inside': 633,\n",
       "             'jimmy': 634,\n",
       "             'led': 635,\n",
       "             'living': 636,\n",
       "             'making': 637,\n",
       "             'male': 638,\n",
       "             'medical': 639,\n",
       "             'month': 640,\n",
       "             'motto': 641,\n",
       "             'museum': 642,\n",
       "             'nationality': 643,\n",
       "             'nine': 644,\n",
       "             'numbers': 645,\n",
       "             'off': 646,\n",
       "             'olympics': 647,\n",
       "             'opera': 648,\n",
       "             'oscar': 649,\n",
       "             'paid': 650,\n",
       "             'planet': 651,\n",
       "             'poet': 652,\n",
       "             'producer': 653,\n",
       "             'products': 654,\n",
       "             'put': 655,\n",
       "             'race': 656,\n",
       "             'roman': 657,\n",
       "             'rule': 658,\n",
       "             'security': 659,\n",
       "             'selling': 660,\n",
       "             'set': 661,\n",
       "             'setting': 662,\n",
       "             'side': 663,\n",
       "             'sound': 664,\n",
       "             'southern': 665,\n",
       "             'spoken': 666,\n",
       "             'stars': 667,\n",
       "             'students': 668,\n",
       "             'tall': 669,\n",
       "             'tallest': 670,\n",
       "             'ten': 671,\n",
       "             'this': 672,\n",
       "             'titled': 673,\n",
       "             'town': 674,\n",
       "             'union': 675,\n",
       "             'van': 676,\n",
       "             'video': 677,\n",
       "             'wars': 678,\n",
       "             'watch': 679,\n",
       "             'wear': 680,\n",
       "             'week': 681,\n",
       "             'weight': 682,\n",
       "             'wife': 683,\n",
       "             '!': 684,\n",
       "             '0': 685,\n",
       "             '11': 686,\n",
       "             '15': 687,\n",
       "             '1899': 688,\n",
       "             '1963': 689,\n",
       "             '1983': 690,\n",
       "             'aaron': 691,\n",
       "             'acid': 692,\n",
       "             'affect': 693,\n",
       "             'alphabet': 694,\n",
       "             'always': 695,\n",
       "             'army': 696,\n",
       "             'ask': 697,\n",
       "             'awarded': 698,\n",
       "             'based': 699,\n",
       "             'birthday': 700,\n",
       "             'books': 701,\n",
       "             'buffalo': 702,\n",
       "             'buy': 703,\n",
       "             'came': 704,\n",
       "             'career': 705,\n",
       "             'castle': 706,\n",
       "             'celebrated': 707,\n",
       "             'chicken': 708,\n",
       "             'cigarette': 709,\n",
       "             'clock': 710,\n",
       "             'columbia': 711,\n",
       "             'comics': 712,\n",
       "             'commercial': 713,\n",
       "             'corpus': 714,\n",
       "             'could': 715,\n",
       "             'cream': 716,\n",
       "             'create': 717,\n",
       "             'cup': 718,\n",
       "             'design': 719,\n",
       "             'diego': 720,\n",
       "             'early': 721,\n",
       "             'elected': 722,\n",
       "             'electric': 723,\n",
       "             'expression': 724,\n",
       "             'field': 725,\n",
       "             'fish': 726,\n",
       "             'florida': 727,\n",
       "             'followed': 728,\n",
       "             'friend': 729,\n",
       "             'gave': 730,\n",
       "             'german': 731,\n",
       "             'glass': 732,\n",
       "             'heart': 733,\n",
       "             'hero': 734,\n",
       "             'historical': 735,\n",
       "             'husband': 736,\n",
       "             'inches': 737,\n",
       "             'india': 738,\n",
       "             'ireland': 739,\n",
       "             'italian': 740,\n",
       "             'kid': 741,\n",
       "             'korea': 742,\n",
       "             'lady': 743,\n",
       "             'lakes': 744,\n",
       "             'least': 745,\n",
       "             'lyrics': 746,\n",
       "             'machines': 747,\n",
       "             'mark': 748,\n",
       "             'mayor': 749,\n",
       "             'mexico': 750,\n",
       "             'milk': 751,\n",
       "             'minimum': 752,\n",
       "             'miss': 753,\n",
       "             'mozambique': 754,\n",
       "             'must': 755,\n",
       "             'near': 756,\n",
       "             'nnp': 757,\n",
       "             'nobel': 758,\n",
       "             'online': 759,\n",
       "             'orange': 760,\n",
       "             'originally': 761,\n",
       "             'our': 762,\n",
       "             'paint': 763,\n",
       "             'party': 764,\n",
       "             'per': 765,\n",
       "             'players': 766,\n",
       "             'police': 767,\n",
       "             'program': 768,\n",
       "             'ray': 769,\n",
       "             'reason': 770,\n",
       "             'richest': 771,\n",
       "             'right': 772,\n",
       "             'salt': 773,\n",
       "             'schools': 774,\n",
       "             'secretary': 775,\n",
       "             'shakespeare': 776,\n",
       "             'she': 777,\n",
       "             'sign': 778,\n",
       "             'sleep': 779,\n",
       "             'small': 780,\n",
       "             'snow': 781,\n",
       "             'society': 782,\n",
       "             'spumante': 783,\n",
       "             'stock': 784,\n",
       "             'successful': 785,\n",
       "             'telephone': 786,\n",
       "             'thomas': 787,\n",
       "             'tokyo': 788,\n",
       "             'told': 789,\n",
       "             'trial': 790,\n",
       "             'vatican': 791,\n",
       "             'wage': 792,\n",
       "             'without': 793,\n",
       "             'written': 794,\n",
       "             '1991': 795,\n",
       "             '21': 796,\n",
       "             '27': 797,\n",
       "             '7': 798,\n",
       "             'album': 799,\n",
       "             'alley': 800,\n",
       "             'amount': 801,\n",
       "             'animated': 802,\n",
       "             'answers.com': 803,\n",
       "             'any': 804,\n",
       "             'atlantic': 805,\n",
       "             'automobile': 806,\n",
       "             'award': 807,\n",
       "             'bay': 808,\n",
       "             'bone': 809,\n",
       "             'border': 810,\n",
       "             'bottle': 811,\n",
       "             'bowling': 812,\n",
       "             'brain': 813,\n",
       "             'broadway': 814,\n",
       "             'bureau': 815,\n",
       "             'cancer': 816,\n",
       "             'caribbean': 817,\n",
       "             'charlie': 818,\n",
       "             'christian': 819,\n",
       "             'church': 820,\n",
       "             'close': 821,\n",
       "             'cocaine': 822,\n",
       "             'committee': 823,\n",
       "             'commonly': 824,\n",
       "             'complete': 825,\n",
       "             'conference': 826,\n",
       "             'contact': 827,\n",
       "             'contain': 828,\n",
       "             'contract': 829,\n",
       "             'control': 830,\n",
       "             'correct': 831,\n",
       "             'd.c.': 832,\n",
       "             'daily': 833,\n",
       "             'daughter': 834,\n",
       "             'dc': 835,\n",
       "             'declared': 836,\n",
       "             'degrees': 837,\n",
       "             'developed': 838,\n",
       "             'diamond': 839,\n",
       "             'discovered': 840,\n",
       "             'don': 841,\n",
       "             'drive': 842,\n",
       "             'drug': 843,\n",
       "             'education': 844,\n",
       "             'elements': 845,\n",
       "             'elephant': 846,\n",
       "             'emperor': 847,\n",
       "             'energy': 848,\n",
       "             'equal': 849,\n",
       "             'events': 850,\n",
       "             'fifth': 851,\n",
       "             'file': 852,\n",
       "             'films': 853,\n",
       "             'fox': 854,\n",
       "             'franklin': 855,\n",
       "             'free': 856,\n",
       "             'gate': 857,\n",
       "             'given': 858,\n",
       "             'going': 859,\n",
       "             'grow': 860,\n",
       "             'gulf': 861,\n",
       "             'harvey': 862,\n",
       "             'having': 863,\n",
       "             'himself': 864,\n",
       "             'hockey': 865,\n",
       "             'host': 866,\n",
       "             'inspired': 867,\n",
       "             'investigation': 868,\n",
       "             'iron': 869,\n",
       "             'italy': 870,\n",
       "             'jane': 871,\n",
       "             'jersey': 872,\n",
       "             'jewish': 873,\n",
       "             'johnny': 874,\n",
       "             'jude': 875,\n",
       "             'justice': 876,\n",
       "             'keep': 877,\n",
       "             'kids': 878,\n",
       "             'large': 879,\n",
       "             'leading': 880,\n",
       "             'leave': 881,\n",
       "             'lee': 882,\n",
       "             'literary': 883,\n",
       "             'madonna': 884,\n",
       "             'magic': 885,\n",
       "             'mary': 886,\n",
       "             'maurizio': 887,\n",
       "             'mccarren': 888,\n",
       "             'meant': 889,\n",
       "             'medicine': 890,\n",
       "             'members': 891,\n",
       "             'michael': 892,\n",
       "             'microsoft': 893,\n",
       "             'model': 894,\n",
       "             'mr.': 895,\n",
       "             'mrs.': 896,\n",
       "             'muppets': 897,\n",
       "             'murder': 898,\n",
       "             'mutombo': 899,\n",
       "             \"n't\": 900,\n",
       "             'nations': 901,\n",
       "             'native': 902,\n",
       "             'nfl': 903,\n",
       "             'occur': 904,\n",
       "             'order': 905,\n",
       "             'owns': 906,\n",
       "             'page': 907,\n",
       "             'painted': 908,\n",
       "             'painting': 909,\n",
       "             'pellegrin': 910,\n",
       "             'perfect': 911,\n",
       "             'period': 912,\n",
       "             'phone': 913,\n",
       "             'poem': 914,\n",
       "             'points': 915,\n",
       "             'pop': 916,\n",
       "             'presidential': 917,\n",
       "             'produces': 918,\n",
       "             'project': 919,\n",
       "             'read': 920,\n",
       "             'received': 921,\n",
       "             'reims': 922,\n",
       "             'religion': 923,\n",
       "             'remove': 924,\n",
       "             'represented': 925,\n",
       "             'research': 926,\n",
       "             'roosevelt': 927,\n",
       "             'salary': 928,\n",
       "             'same': 929,\n",
       "             'score': 930,\n",
       "             'seen': 931,\n",
       "             'serve': 932,\n",
       "             'sex': 933,\n",
       "             'silly': 934,\n",
       "             'silver': 935,\n",
       "             'simpsons': 936,\n",
       "             'single': 937,\n",
       "             'sister': 938,\n",
       "             'site': 939,\n",
       "             'sold': 940,\n",
       "             'spain': 941,\n",
       "             'spielberg': 942,\n",
       "             'submarine': 943,\n",
       "             'swimming': 944,\n",
       "             'tale': 945,\n",
       "             'taste': 946,\n",
       "             'temperature': 947,\n",
       "             'took': 948,\n",
       "             'treat': 949,\n",
       "             'turned': 950,\n",
       "             'twins': 951,\n",
       "             'universe': 952,\n",
       "             'usa': 953,\n",
       "             'using': 954,\n",
       "             'vegas': 955,\n",
       "             'vhs': 956,\n",
       "             'visit': 957,\n",
       "             'voice': 958,\n",
       "             'watergate': 959,\n",
       "             'ways': 960,\n",
       "             'wings': 961,\n",
       "             'working': 962,\n",
       "             'yankee': 963,\n",
       "             \"'ll\": 964,\n",
       "             '..': 965,\n",
       "             '000': 966,\n",
       "             '12': 967,\n",
       "             '13': 968,\n",
       "             '16th': 969,\n",
       "             '1939': 970,\n",
       "             '1960': 971,\n",
       "             '1965': 972,\n",
       "             '1967': 973,\n",
       "             '1969': 974,\n",
       "             '1980': 975,\n",
       "             '1994': 976,\n",
       "             '1998': 977,\n",
       "             '2000': 978,\n",
       "             'academy': 979,\n",
       "             'act': 980,\n",
       "             'ads': 981,\n",
       "             'adult': 982,\n",
       "             'advertise': 983,\n",
       "             'against': 984,\n",
       "             'ages': 985,\n",
       "             'ago': 986,\n",
       "             'airplane': 987,\n",
       "             'al': 988,\n",
       "             'along': 989,\n",
       "             'amendment': 990,\n",
       "             'appearance': 991,\n",
       "             'appeared': 992,\n",
       "             'arch': 993,\n",
       "             'arthur': 994,\n",
       "             'asia': 995,\n",
       "             'asked': 996,\n",
       "             'aspartame': 997,\n",
       "             'associated': 998,\n",
       "             'astronauts': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocab dictionaries\n",
    "text_field.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embeddings): Embedding(5002, 6)\n",
       "  (rnn): LSTM(6, 6, batch_first=True)\n",
       "  (linear): Linear(in_features=6, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_tokens, embedding_dim, rnn_dim, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_tokens, embedding_dim)\n",
    "        self.rnn = nn.LSTM(input_size = embedding_dim,\n",
    "                           hidden_size = rnn_dim, \n",
    "                           num_layers = num_layers,\n",
    "                           batch_first = True,\n",
    "                           bidirectional=False)\n",
    "        self.linear = nn.Linear(rnn_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embeddings(x)\n",
    "        rnn_output, rnn_hidden = self.rnn(emb) \n",
    "        x = rnn_output[:,-1,:]\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "model = RNN(word_count, 6, 6, 1, classes_count)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Objective function (and optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_decay = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train model (and test during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_iter = data.BucketIterator(train, \n",
    "                                 batch_size=batch_size, \n",
    "                                 sort_within_batch=True, \n",
    "                                 shuffle = True, \n",
    "                                 repeat = False)\n",
    "\n",
    "test_iter = data.BucketIterator(test, \n",
    "                          batch_size=30, \n",
    "                          sort_within_batch=True, \n",
    "                          shuffle = True, \n",
    "                          repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset variables \n",
    "accuracies = []\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "train_accuracy = 0\n",
    "step_count = 0\n",
    "max_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch  0\n",
      "Step:  0 Accuracy in test set: 0.16200000047683716\n",
      "Step:  100 Accuracy in test set: 0.2759999930858612\n",
      "Training epoch  1\n",
      "Step:  200 Accuracy in test set: 0.30799999833106995\n",
      "Step:  300 Accuracy in test set: 0.30799999833106995\n",
      "Training epoch  2\n",
      "Step:  400 Accuracy in test set: 0.29600000381469727\n",
      "Step:  500 Accuracy in test set: 0.335999995470047\n",
      "Training epoch  3\n",
      "Step:  600 Accuracy in test set: 0.3540000021457672\n",
      "Training epoch  4\n",
      "Step:  700 Accuracy in test set: 0.35600000619888306\n",
      "Step:  800 Accuracy in test set: 0.3479999899864197\n",
      "Training epoch  5\n",
      "Step:  900 Accuracy in test set: 0.36000001430511475\n",
      "Step:  1000 Accuracy in test set: 0.36800000071525574\n",
      "Training epoch  6\n",
      "Step:  1100 Accuracy in test set: 0.40400001406669617\n",
      "Training epoch  7\n",
      "Step:  1200 Accuracy in test set: 0.42800000309944153\n",
      "Step:  1300 Accuracy in test set: 0.4560000002384186\n",
      "Training epoch  8\n",
      "Step:  1400 Accuracy in test set: 0.4860000014305115\n",
      "Step:  1500 Accuracy in test set: 0.4880000054836273\n",
      "Training epoch  9\n",
      "Step:  1600 Accuracy in test set: 0.5019999742507935\n",
      "Step:  1700 Accuracy in test set: 0.5059999823570251\n",
      "Training epoch  10\n",
      "Step:  1800 Accuracy in test set: 0.5320000052452087\n",
      "Training epoch  11\n",
      "Step:  1900 Accuracy in test set: 0.5339999794960022\n",
      "Step:  2000 Accuracy in test set: 0.5360000133514404\n",
      "Training epoch  12\n",
      "Step:  2100 Accuracy in test set: 0.5519999861717224\n",
      "Step:  2200 Accuracy in test set: 0.5680000185966492\n",
      "Training epoch  13\n",
      "Step:  2300 Accuracy in test set: 0.5640000104904175\n",
      "Training epoch  14\n",
      "Step:  2400 Accuracy in test set: 0.5519999861717224\n",
      "Step:  2500 Accuracy in test set: 0.5559999942779541\n",
      "Training epoch  15\n",
      "Step:  2600 Accuracy in test set: 0.5580000281333923\n",
      "Step:  2700 Accuracy in test set: 0.5600000023841858\n",
      "Training epoch  16\n",
      "Step:  2800 Accuracy in test set: 0.5659999847412109\n",
      "Step:  2900 Accuracy in test set: 0.5699999928474426\n",
      "Training epoch  17\n",
      "Step:  3000 Accuracy in test set: 0.5580000281333923\n",
      "Training epoch  18\n",
      "Step:  3100 Accuracy in test set: 0.5640000104904175\n",
      "Step:  3200 Accuracy in test set: 0.550000011920929\n",
      "Training epoch  19\n",
      "Step:  3300 Accuracy in test set: 0.5640000104904175\n",
      "Step:  3400 Accuracy in test set: 0.5659999847412109\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "for i in range(num_epochs):\n",
    "    print('Training epoch ',i)\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:        \n",
    "\n",
    "        x_train = batch.text\n",
    "        y_train = batch.label\n",
    "\n",
    "        # Forward pass\n",
    "        y_model = model(x_train)\n",
    "\n",
    "        # Loss function\n",
    "        loss = loss_function(y_model, y_train)\n",
    "        losses_train.append(float(loss))\n",
    "\n",
    "        # Backward pass \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluation in test set\n",
    "\n",
    "        if step_count%100 == 0:\n",
    "\n",
    "            # Calculate model in test set by pieces\n",
    "            model.eval() # Set model to eval (if there is dropout, will set it to zero)\n",
    "            y_model_test_list = []\n",
    "            y_test_list = []\n",
    "            \n",
    "            for test_batch in test_iter:            \n",
    "                y_model_test_list.append(model(test_batch.text))            \n",
    "                y_test_list.append(test_batch.label)\n",
    "            model.train() # Set model to train (if there is dropout, will not be zero anymore)\n",
    "            test_iter.init_epoch()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = float( (torch.cat(y_model_test_list).max(dim=1)[1] == torch.cat(y_test_list)).float().mean() )\n",
    "            print('Step: ', step_count, 'Accuracy in test set:', accuracy)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        lr_decay.step()\n",
    "        step_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1306a0588>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice: Improve your RNN \n",
    "\n",
    "Improve your recurrent network:\n",
    "* Apply dropout between the LSTM and the linear layer\n",
    "* Add more complexity to the model (RNN layers, other layers)\n",
    "* Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embeddings): Embedding(5002, 50)\n",
       "  (rnn): LSTM(50, 20, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear): Linear(in_features=40, out_features=20, bias=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (linear2): Linear(in_features=20, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_tokens, embedding_dim, rnn_dim, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_tokens, embedding_dim)\n",
    "        self.rnn = nn.LSTM(input_size = embedding_dim,\n",
    "                           hidden_size = rnn_dim, \n",
    "                           num_layers = num_layers,\n",
    "                           batch_first = True,\n",
    "                           bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(2*rnn_dim, rnn_dim)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.linear2 = nn.Linear(rnn_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embeddings(x)\n",
    "        rnn_output, rnn_hidden = self.rnn(emb) \n",
    "        x = self.dropout(rnn_output)\n",
    "        x = self.linear(rnn_output[:,-1,:])\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = RNN(word_count, 50, 20, 3, classes_count)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_decay = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_iter = data.BucketIterator(train, \n",
    "                                 batch_size=batch_size, \n",
    "                                 sort_within_batch=True, \n",
    "                                 shuffle = True, \n",
    "                                 repeat = False)\n",
    "\n",
    "test_iter = data.BucketIterator(test, \n",
    "                          batch_size=30, \n",
    "                          sort_within_batch=True, \n",
    "                          shuffle = True, \n",
    "                          repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset variables \n",
    "accuracies = []\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "train_accuracy = 0\n",
    "step_count = 0\n",
    "max_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch  0\n",
      "Step:  0 Accuracy in test set: 0.2759999930858612\n",
      "Step:  100 Accuracy in test set: 0.12999999523162842\n",
      "Training epoch  1\n",
      "Step:  200 Accuracy in test set: 0.3700000047683716\n",
      "Step:  300 Accuracy in test set: 0.5659999847412109\n",
      "Training epoch  2\n",
      "Step:  400 Accuracy in test set: 0.5799999833106995\n",
      "Step:  500 Accuracy in test set: 0.5899999737739563\n",
      "Training epoch  3\n",
      "Step:  600 Accuracy in test set: 0.6240000128746033\n",
      "Training epoch  4\n",
      "Step:  700 Accuracy in test set: 0.628000020980835\n",
      "Step:  800 Accuracy in test set: 0.656000018119812\n",
      "Training epoch  5\n",
      "Step:  900 Accuracy in test set: 0.6779999732971191\n",
      "Step:  1000 Accuracy in test set: 0.7179999947547913\n",
      "Training epoch  6\n",
      "Step:  1100 Accuracy in test set: 0.7160000205039978\n",
      "Training epoch  7\n",
      "Step:  1200 Accuracy in test set: 0.7319999933242798\n",
      "Step:  1300 Accuracy in test set: 0.734000027179718\n",
      "Training epoch  8\n",
      "Step:  1400 Accuracy in test set: 0.7039999961853027\n",
      "Step:  1500 Accuracy in test set: 0.765999972820282\n",
      "Training epoch  9\n",
      "Step:  1600 Accuracy in test set: 0.7400000095367432\n",
      "Step:  1700 Accuracy in test set: 0.7639999985694885\n",
      "Training epoch  10\n",
      "Step:  1800 Accuracy in test set: 0.7720000147819519\n",
      "Training epoch  11\n",
      "Step:  1900 Accuracy in test set: 0.7900000214576721\n",
      "Step:  2000 Accuracy in test set: 0.777999997138977\n",
      "Training epoch  12\n",
      "Step:  2100 Accuracy in test set: 0.7799999713897705\n",
      "Step:  2200 Accuracy in test set: 0.7760000228881836\n",
      "Training epoch  13\n",
      "Step:  2300 Accuracy in test set: 0.7860000133514404\n",
      "Training epoch  14\n",
      "Step:  2400 Accuracy in test set: 0.7960000038146973\n",
      "Step:  2500 Accuracy in test set: 0.7839999794960022\n",
      "Training epoch  15\n",
      "Step:  2600 Accuracy in test set: 0.7900000214576721\n",
      "Step:  2700 Accuracy in test set: 0.7820000052452087\n",
      "Training epoch  16\n",
      "Step:  2800 Accuracy in test set: 0.7820000052452087\n",
      "Step:  2900 Accuracy in test set: 0.7960000038146973\n",
      "Training epoch  17\n",
      "Step:  3000 Accuracy in test set: 0.800000011920929\n",
      "Training epoch  18\n",
      "Step:  3100 Accuracy in test set: 0.7839999794960022\n",
      "Step:  3200 Accuracy in test set: 0.7960000038146973\n",
      "Training epoch  19\n",
      "Step:  3300 Accuracy in test set: 0.7820000052452087\n",
      "Step:  3400 Accuracy in test set: 0.7940000295639038\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for i in range(num_epochs):\n",
    "    print('Training epoch ',i)\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:        \n",
    "\n",
    "        x_train = batch.text\n",
    "        y_train = batch.label\n",
    "\n",
    "        # Forward pass\n",
    "        y_model = model(x_train)\n",
    "\n",
    "        # Loss function\n",
    "        loss = loss_function(y_model, y_train)\n",
    "        losses_train.append(float(loss))\n",
    "\n",
    "        # Backward pass \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluation in test set\n",
    "\n",
    "        if step_count%100 == 0:\n",
    "\n",
    "            # Calculate model in test set by pieces\n",
    "            model.eval() # Set model to eval (if there is dropout, will set it to zero)\n",
    "            y_model_test_list = []\n",
    "            y_test_list = []\n",
    "            \n",
    "            for test_batch in test_iter:            \n",
    "                y_model_test_list.append(model(test_batch.text))            \n",
    "                y_test_list.append(test_batch.label)\n",
    "            model.train() # Set model to train (if there is dropout, will not be zero anymore)\n",
    "            test_iter.init_epoch()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = float( (torch.cat(y_model_test_list).max(dim=1)[1] == torch.cat(y_test_list)).float().mean() )\n",
    "            print('Step: ', step_count, 'Accuracy in test set:', accuracy)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        lr_decay.step()\n",
    "        step_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
