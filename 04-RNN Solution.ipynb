{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cenkbircanoglu/pytorch-workshop/blob/master/04-RNN%20Solution.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to build a model to classify text, using the TREC-6 dataset.\n",
    "\n",
    "The TREC-6 dataset consist on a set of 5,952 questions written in English, classified in the following categories, depending on the answer:\n",
    "\n",
    "* HUM: Human\n",
    "* DESC: Description\n",
    "* ABBR: Abbreviation\n",
    "* LOC: Location\n",
    "* NUM: Number\n",
    "* ENTY: Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: spacy in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (1.17.4)\n",
      "Requirement already satisfied: torch in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (1.3.1)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (4.40.1)\n",
      "Requirement already satisfied: six in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (1.13.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (0.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (42.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (8.0.2)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.17.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (42.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.40.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (8.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 18.1, however version 19.3.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\r\n",
      "You can now load the model via spacy.load('en_core_web_sm')\r\n",
      "\u001b[38;5;2m[+] Linking successful\u001b[0m\r\n",
      "/home/ubuntu/.pyenv/versions/learn-pytorch/lib/python3.6/site-packages/en_core_web_sm\r\n",
      "-->\r\n",
      "/home/ubuntu/.pyenv/versions/learn-pytorch/lib/python3.6/site-packages/spacy/data/en\r\n",
      "You can now load the model via spacy.load('en')\r\n"
     ]
    }
   ],
   "source": [
    "# The following lines will install the torchtext and spacy libraries, \n",
    "# used to prepare text datasets for models in PyTorch.\n",
    "\n",
    "!pip install torchtext spacy\n",
    "#!conda install -c conda-forge spacy -y\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 5452\n",
      "Test length: 500\n"
     ]
    }
   ],
   "source": [
    "# Get datasets\n",
    "text_field = data.Field(lower=True, batch_first=True, tokenize='spacy')\n",
    "label_field = data.Field(sequential=False, unk_token = None)\n",
    "train, test = datasets.TREC.splits(text_field, label_field)\n",
    "\n",
    "print('Train length:',str(len(train)))\n",
    "print('Test length:',str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how big is the largest diamond ? NUM\n",
      "what dickens novel has david carrying the message ` ` barkis is willin '' to peggy ? ENTY\n",
      "how do hermit crabs reproduce ? DESC\n",
      "what is a fear of fur ? ENTY\n",
      "which type of submarine was bought recently by south korea ? ENTY\n",
      "how many colors are there in a rainbow ? NUM\n",
      "how can you define time ? DESC\n",
      "which city has the oldest relationship as a sister city with los angeles ? LOC\n",
      "what is the weight of air ? NUM\n",
      "how is cologne made ? DESC\n"
     ]
    }
   ],
   "source": [
    "# Show some examples\n",
    "\n",
    "for i in range(10):\n",
    "    random_index = random.randint(0,len(train))\n",
    "    print(' '.join(train.examples[random_index].text), train.examples[random_index].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 5002\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "vocab_length = 5000\n",
    "text_field.build_vocab(train, max_size=vocab_length)\n",
    "label_field.build_vocab(train)\n",
    "\n",
    "classes_count = len(label_field.vocab)\n",
    "word_count = len(text_field.vocab)\n",
    "print('Vocabulary length:', word_count)\n",
    "print('Number of classes:', classes_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f121a84a940>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             '?': 2,\n",
       "             'the': 3,\n",
       "             'what': 4,\n",
       "             'is': 5,\n",
       "             'of': 6,\n",
       "             'in': 7,\n",
       "             'a': 8,\n",
       "             '`': 9,\n",
       "             'how': 10,\n",
       "             \"'s\": 11,\n",
       "             'was': 12,\n",
       "             'to': 13,\n",
       "             'who': 14,\n",
       "             ',': 15,\n",
       "             'are': 16,\n",
       "             'for': 17,\n",
       "             'and': 18,\n",
       "             \"''\": 19,\n",
       "             'does': 20,\n",
       "             'did': 21,\n",
       "             '-': 22,\n",
       "             'do': 23,\n",
       "             'many': 24,\n",
       "             'name': 25,\n",
       "             'on': 26,\n",
       "             'where': 27,\n",
       "             'i': 28,\n",
       "             'first': 29,\n",
       "             'you': 30,\n",
       "             'can': 31,\n",
       "             'when': 32,\n",
       "             'world': 33,\n",
       "             'from': 34,\n",
       "             'which': 35,\n",
       "             'by': 36,\n",
       "             'that': 37,\n",
       "             'u.s.': 38,\n",
       "             'country': 39,\n",
       "             'most': 40,\n",
       "             'an': 41,\n",
       "             'as': 42,\n",
       "             'with': 43,\n",
       "             'have': 44,\n",
       "             'city': 45,\n",
       "             '.': 46,\n",
       "             'has': 47,\n",
       "             'why': 48,\n",
       "             \"'\": 49,\n",
       "             'it': 50,\n",
       "             'there': 51,\n",
       "             'be': 52,\n",
       "             'people': 53,\n",
       "             'get': 54,\n",
       "             'at': 55,\n",
       "             'were': 56,\n",
       "             'find': 57,\n",
       "             'called': 58,\n",
       "             'his': 59,\n",
       "             'year': 60,\n",
       "             'state': 61,\n",
       "             'president': 62,\n",
       "             'american': 63,\n",
       "             'two': 64,\n",
       "             'largest': 65,\n",
       "             'mean': 66,\n",
       "             'war': 67,\n",
       "             'fear': 68,\n",
       "             'made': 69,\n",
       "             'new': 70,\n",
       "             'much': 71,\n",
       "             'long': 72,\n",
       "             'between': 73,\n",
       "             ':': 74,\n",
       "             'its': 75,\n",
       "             'origin': 76,\n",
       "             'used': 77,\n",
       "             'word': 78,\n",
       "             'about': 79,\n",
       "             'company': 80,\n",
       "             'known': 81,\n",
       "             'movie': 82,\n",
       "             'tv': 83,\n",
       "             'film': 84,\n",
       "             'kind': 85,\n",
       "             'one': 86,\n",
       "             'all': 87,\n",
       "             'famous': 88,\n",
       "             'best': 89,\n",
       "             'day': 90,\n",
       "             'or': 91,\n",
       "             'make': 92,\n",
       "             'take': 93,\n",
       "             'game': 94,\n",
       "             'he': 95,\n",
       "             'stand': 96,\n",
       "             'time': 97,\n",
       "             'up': 98,\n",
       "             'your': 99,\n",
       "             'live': 100,\n",
       "             'invented': 101,\n",
       "             'man': 102,\n",
       "             'book': 103,\n",
       "             'come': 104,\n",
       "             'only': 105,\n",
       "             'color': 106,\n",
       "             'john': 107,\n",
       "             'my': 108,\n",
       "             'not': 109,\n",
       "             'into': 110,\n",
       "             'old': 111,\n",
       "             'out': 112,\n",
       "             'play': 113,\n",
       "             'show': 114,\n",
       "             'term': 115,\n",
       "             'their': 116,\n",
       "             'wrote': 117,\n",
       "             'states': 118,\n",
       "             'countries': 119,\n",
       "             'last': 120,\n",
       "             'star': 121,\n",
       "             'america': 122,\n",
       "             'four': 123,\n",
       "             'home': 124,\n",
       "             'if': 125,\n",
       "             'named': 126,\n",
       "             'south': 127,\n",
       "             'won': 128,\n",
       "             'call': 129,\n",
       "             'highest': 130,\n",
       "             'team': 131,\n",
       "             'baseball': 132,\n",
       "             'character': 133,\n",
       "             'difference': 134,\n",
       "             'had': 135,\n",
       "             'king': 136,\n",
       "             'number': 137,\n",
       "             'river': 138,\n",
       "             'after': 139,\n",
       "             'english': 140,\n",
       "             'use': 141,\n",
       "             'born': 142,\n",
       "             'three': 143,\n",
       "             'died': 144,\n",
       "             'information': 145,\n",
       "             'novel': 146,\n",
       "             'played': 147,\n",
       "             'said': 148,\n",
       "             'some': 149,\n",
       "             'song': 150,\n",
       "             'work': 151,\n",
       "             'been': 152,\n",
       "             'black': 153,\n",
       "             'united': 154,\n",
       "             'actor': 155,\n",
       "             'average': 156,\n",
       "             'become': 157,\n",
       "             'capital': 158,\n",
       "             'college': 159,\n",
       "             'common': 160,\n",
       "             'dog': 161,\n",
       "             'say': 162,\n",
       "             'us': 163,\n",
       "             'will': 164,\n",
       "             'years': 165,\n",
       "             '1': 166,\n",
       "             'actress': 167,\n",
       "             'body': 168,\n",
       "             'computer': 169,\n",
       "             'earth': 170,\n",
       "             'go': 171,\n",
       "             'names': 172,\n",
       "             'population': 173,\n",
       "             'second': 174,\n",
       "             'water': 175,\n",
       "             'california': 176,\n",
       "             'drink': 177,\n",
       "             'food': 178,\n",
       "             'group': 179,\n",
       "             'located': 180,\n",
       "             'mountain': 181,\n",
       "             'sport': 182,\n",
       "             't': 183,\n",
       "             'they': 184,\n",
       "             'woman': 185,\n",
       "             'would': 186,\n",
       "             'die': 187,\n",
       "             'during': 188,\n",
       "             'good': 189,\n",
       "             'island': 190,\n",
       "             'like': 191,\n",
       "             'north': 192,\n",
       "             'space': 193,\n",
       "             'than': 194,\n",
       "             'times': 195,\n",
       "             'top': 196,\n",
       "             'york': 197,\n",
       "             'animal': 198,\n",
       "             'killed': 199,\n",
       "             'longest': 200,\n",
       "             'money': 201,\n",
       "             'school': 202,\n",
       "             'sea': 203,\n",
       "             'great': 204,\n",
       "             'history': 205,\n",
       "             'law': 206,\n",
       "             'more': 207,\n",
       "             'over': 208,\n",
       "             'part': 209,\n",
       "             'popular': 210,\n",
       "             'portrayed': 211,\n",
       "             'through': 212,\n",
       "             'university': 213,\n",
       "             'big': 214,\n",
       "             'different': 215,\n",
       "             'her': 216,\n",
       "             'language': 217,\n",
       "             'major': 218,\n",
       "             'makes': 219,\n",
       "             'person': 220,\n",
       "             'red': 221,\n",
       "             'should': 222,\n",
       "             'way': 223,\n",
       "             'car': 224,\n",
       "             'cities': 225,\n",
       "             'date': 226,\n",
       "             'each': 227,\n",
       "             'five': 228,\n",
       "             'general': 229,\n",
       "             'horse': 230,\n",
       "             'internet': 231,\n",
       "             'line': 232,\n",
       "             'meaning': 233,\n",
       "             'national': 234,\n",
       "             'title': 235,\n",
       "             'west': 236,\n",
       "             'address': 237,\n",
       "             'became': 238,\n",
       "             'charles': 239,\n",
       "             'contains': 240,\n",
       "             'cost': 241,\n",
       "             'craft': 242,\n",
       "             'created': 243,\n",
       "             'french': 244,\n",
       "             'international': 245,\n",
       "             'leader': 246,\n",
       "             'life': 247,\n",
       "             'miles': 248,\n",
       "             'russian': 249,\n",
       "             'so': 250,\n",
       "             'write': 251,\n",
       "             'battle': 252,\n",
       "             'biggest': 253,\n",
       "             'built': 254,\n",
       "             'causes': 255,\n",
       "             'letter': 256,\n",
       "             'me': 257,\n",
       "             'place': 258,\n",
       "             'randy': 259,\n",
       "             'white': 260,\n",
       "             'whose': 261,\n",
       "             'abbreviation': 262,\n",
       "             'airport': 263,\n",
       "             'bridge': 264,\n",
       "             'century': 265,\n",
       "             'features': 266,\n",
       "             'feet': 267,\n",
       "             'form': 268,\n",
       "             'found': 269,\n",
       "             'games': 270,\n",
       "             'ii': 271,\n",
       "             'little': 272,\n",
       "             'moon': 273,\n",
       "             'power': 274,\n",
       "             'queen': 275,\n",
       "             'seven': 276,\n",
       "             'system': 277,\n",
       "             '5': 278,\n",
       "             'air': 279,\n",
       "             'baby': 280,\n",
       "             'begin': 281,\n",
       "             'boasts': 282,\n",
       "             'british': 283,\n",
       "             'children': 284,\n",
       "             'colors': 285,\n",
       "             'comic': 286,\n",
       "             'death': 287,\n",
       "             'e': 288,\n",
       "             'eat': 289,\n",
       "             'england': 290,\n",
       "             'following': 291,\n",
       "             'george': 292,\n",
       "             'germany': 293,\n",
       "             'high': 294,\n",
       "             'human': 295,\n",
       "             'james': 296,\n",
       "             'kennedy': 297,\n",
       "             'league': 298,\n",
       "             'london': 299,\n",
       "             'love': 300,\n",
       "             'men': 301,\n",
       "             'nickname': 302,\n",
       "             'nixon': 303,\n",
       "             'no': 304,\n",
       "             'office': 305,\n",
       "             'park': 306,\n",
       "             'player': 307,\n",
       "             'san': 308,\n",
       "             'someone': 309,\n",
       "             'spanish': 310,\n",
       "             'type': 311,\n",
       "             '2': 312,\n",
       "             'area': 313,\n",
       "             'blood': 314,\n",
       "             'bowl': 315,\n",
       "             'disease': 316,\n",
       "             'european': 317,\n",
       "             'held': 318,\n",
       "             'hit': 319,\n",
       "             'hole': 320,\n",
       "             'house': 321,\n",
       "             'islands': 322,\n",
       "             'japanese': 323,\n",
       "             'letters': 324,\n",
       "             'may': 325,\n",
       "             'mother': 326,\n",
       "             'nn': 327,\n",
       "             'product': 328,\n",
       "             'rate': 329,\n",
       "             'real': 330,\n",
       "             'soft': 331,\n",
       "             'television': 332,\n",
       "             'washington': 333,\n",
       "             'animals': 334,\n",
       "             'before': 335,\n",
       "             'bill': 336,\n",
       "             'business': 337,\n",
       "             'center': 338,\n",
       "             'chemical': 339,\n",
       "             'father': 340,\n",
       "             'female': 341,\n",
       "             'happened': 342,\n",
       "             'know': 343,\n",
       "             'lawyer': 344,\n",
       "             'married': 345,\n",
       "             'member': 346,\n",
       "             'o': 347,\n",
       "             'ocean': 348,\n",
       "             'st.': 349,\n",
       "             'super': 350,\n",
       "             'william': 351,\n",
       "             'words': 352,\n",
       "             '&': 353,\n",
       "             'age': 354,\n",
       "             'building': 355,\n",
       "             'christmas': 356,\n",
       "             'definition': 357,\n",
       "             'ever': 358,\n",
       "             'hitler': 359,\n",
       "             'ice': 360,\n",
       "             'lives': 361,\n",
       "             'music': 362,\n",
       "             'newspaper': 363,\n",
       "             'once': 364,\n",
       "             'runs': 365,\n",
       "             'series': 366,\n",
       "             'served': 367,\n",
       "             'singing': 368,\n",
       "             'soldiers': 369,\n",
       "             'tree': 370,\n",
       "             'whom': 371,\n",
       "             'win': 372,\n",
       "             '$': 373,\n",
       "             'africa': 374,\n",
       "             'another': 375,\n",
       "             'around': 376,\n",
       "             'ball': 377,\n",
       "             'beer': 378,\n",
       "             'being': 379,\n",
       "             'birth': 380,\n",
       "             'boy': 381,\n",
       "             'canada': 382,\n",
       "             'civil': 383,\n",
       "             'cnn': 384,\n",
       "             'code': 385,\n",
       "             'county': 386,\n",
       "             'dick': 387,\n",
       "             'end': 388,\n",
       "             'f.': 389,\n",
       "             'far': 390,\n",
       "             'girl': 391,\n",
       "             'greek': 392,\n",
       "             'indians': 393,\n",
       "             'jack': 394,\n",
       "             'main': 395,\n",
       "             'minister': 396,\n",
       "             'mississippi': 397,\n",
       "             'night': 398,\n",
       "             'oldest': 399,\n",
       "             'original': 400,\n",
       "             'other': 401,\n",
       "             'prime': 402,\n",
       "             'prize': 403,\n",
       "             'radio': 404,\n",
       "             'rock': 405,\n",
       "             'ship': 406,\n",
       "             'singer': 407,\n",
       "             'six': 408,\n",
       "             'sports': 409,\n",
       "             'store': 410,\n",
       "             'tell': 411,\n",
       "             'them': 412,\n",
       "             'travel': 413,\n",
       "             'tuberculosis': 414,\n",
       "             'we': 415,\n",
       "             'web': 416,\n",
       "             '10': 417,\n",
       "             '3': 418,\n",
       "             'art': 419,\n",
       "             'back': 420,\n",
       "             'basketball': 421,\n",
       "             'bible': 422,\n",
       "             'board': 423,\n",
       "             'but': 424,\n",
       "             'card': 425,\n",
       "             'cartoon': 426,\n",
       "             'china': 427,\n",
       "             'claim': 428,\n",
       "             'cold': 429,\n",
       "             'comedian': 430,\n",
       "             'cross': 431,\n",
       "             'department': 432,\n",
       "             'down': 433,\n",
       "             'east': 434,\n",
       "             'fame': 435,\n",
       "             'famed': 436,\n",
       "             'fast': 437,\n",
       "             'flag': 438,\n",
       "             'football': 439,\n",
       "             'former': 440,\n",
       "             'founded': 441,\n",
       "             'god': 442,\n",
       "             'gold': 443,\n",
       "             'indian': 444,\n",
       "             'introduced': 445,\n",
       "             'kentucky': 446,\n",
       "             'lake': 447,\n",
       "             'marvel': 448,\n",
       "             'musical': 449,\n",
       "             'never': 450,\n",
       "             'now': 451,\n",
       "             'olympic': 452,\n",
       "             'originate': 453,\n",
       "             'percentage': 454,\n",
       "             'pope': 455,\n",
       "             'produce': 456,\n",
       "             'richard': 457,\n",
       "             'role': 458,\n",
       "             'saw': 459,\n",
       "             'see': 460,\n",
       "             'size': 461,\n",
       "             'son': 462,\n",
       "             'starred': 463,\n",
       "             'story': 464,\n",
       "             'tax': 465,\n",
       "             'then': 466,\n",
       "             'thing': 467,\n",
       "             'while': 468,\n",
       "             '1984': 469,\n",
       "             'americans': 470,\n",
       "             'appear': 471,\n",
       "             'author': 472,\n",
       "             'bear': 473,\n",
       "             'berlin': 474,\n",
       "             'blue': 475,\n",
       "             'brothers': 476,\n",
       "             'cards': 477,\n",
       "             'caused': 478,\n",
       "             'child': 479,\n",
       "             'chinese': 480,\n",
       "             'director': 481,\n",
       "             'dubbed': 482,\n",
       "             'europe': 483,\n",
       "             'every': 484,\n",
       "             'family': 485,\n",
       "             'fastest': 486,\n",
       "             'favorite': 487,\n",
       "             'fought': 488,\n",
       "             'full': 489,\n",
       "             'give': 490,\n",
       "             'golf': 491,\n",
       "             'hair': 492,\n",
       "             'head': 493,\n",
       "             'income': 494,\n",
       "             'japan': 495,\n",
       "             'latin': 496,\n",
       "             'list': 497,\n",
       "             'lived': 498,\n",
       "             'look': 499,\n",
       "             'los': 500,\n",
       "             'mile': 501,\n",
       "             'mount': 502,\n",
       "             'need': 503,\n",
       "             'organization': 504,\n",
       "             'own': 505,\n",
       "             'record': 506,\n",
       "             'shot': 507,\n",
       "             'sioux': 508,\n",
       "             'sometimes': 509,\n",
       "             'soviet': 510,\n",
       "             'species': 511,\n",
       "             'start': 512,\n",
       "             'started': 513,\n",
       "             'steven': 514,\n",
       "             'street': 515,\n",
       "             'strip': 516,\n",
       "             'symbol': 517,\n",
       "             'texas': 518,\n",
       "             'tom': 519,\n",
       "             'under': 520,\n",
       "             'vietnam': 521,\n",
       "             'website': 522,\n",
       "             'went': 523,\n",
       "             'wine': 524,\n",
       "             'women': 525,\n",
       "             'worth': 526,\n",
       "             '6': 527,\n",
       "             '8': 528,\n",
       "             'african': 529,\n",
       "             'angeles': 530,\n",
       "             'asian': 531,\n",
       "             'australia': 532,\n",
       "             'band': 533,\n",
       "             'beach': 534,\n",
       "             'because': 535,\n",
       "             'believe': 536,\n",
       "             'birds': 537,\n",
       "             'boxing': 538,\n",
       "             'brand': 539,\n",
       "             'captain': 540,\n",
       "             'characters': 541,\n",
       "             'chicago': 542,\n",
       "             'continent': 543,\n",
       "             'court': 544,\n",
       "             'days': 545,\n",
       "             'de': 546,\n",
       "             'desert': 547,\n",
       "             'eggs': 548,\n",
       "             'el': 549,\n",
       "             'eyes': 550,\n",
       "             'fire': 551,\n",
       "             'flight': 552,\n",
       "             'fly': 553,\n",
       "             'france': 554,\n",
       "             'gas': 555,\n",
       "             'gould': 556,\n",
       "             'government': 557,\n",
       "             'greatest': 558,\n",
       "             'green': 559,\n",
       "             'hand': 560,\n",
       "             'hands': 561,\n",
       "             'henry': 562,\n",
       "             'instrument': 563,\n",
       "             'jackson': 564,\n",
       "             'jaws': 565,\n",
       "             'languages': 566,\n",
       "             'left': 567,\n",
       "             'light': 568,\n",
       "             'lost': 569,\n",
       "             'magazine': 570,\n",
       "             'mail': 571,\n",
       "             'march': 572,\n",
       "             'massachusetts': 573,\n",
       "             'middle': 574,\n",
       "             'million': 575,\n",
       "             'monopoly': 576,\n",
       "             'months': 577,\n",
       "             'nuclear': 578,\n",
       "             'often': 579,\n",
       "             'oil': 580,\n",
       "             'paper': 581,\n",
       "             'peter': 582,\n",
       "             'plant': 583,\n",
       "             'plays': 584,\n",
       "             'point': 585,\n",
       "             'presidents': 586,\n",
       "             'prince': 587,\n",
       "             'produced': 588,\n",
       "             'rights': 589,\n",
       "             'run': 590,\n",
       "             'shea': 591,\n",
       "             'square': 592,\n",
       "             'stop': 593,\n",
       "             'sun': 594,\n",
       "             'tennis': 595,\n",
       "             'thatcher': 596,\n",
       "             'types': 597,\n",
       "             'wall': 598,\n",
       "             'winter': 599,\n",
       "             'writer': 600,\n",
       "             'aids': 601,\n",
       "             'alaska': 602,\n",
       "             'allowed': 603,\n",
       "             'also': 604,\n",
       "             'artist': 605,\n",
       "             'assassinated': 606,\n",
       "             'balls': 607,\n",
       "             'bond': 608,\n",
       "             'brown': 609,\n",
       "             'build': 610,\n",
       "             'buried': 611,\n",
       "             'cars': 612,\n",
       "             'cat': 613,\n",
       "             'claimed': 614,\n",
       "             'comes': 615,\n",
       "             'companies': 616,\n",
       "             'considered': 617,\n",
       "             'cover': 618,\n",
       "             'cowboy': 619,\n",
       "             'current': 620,\n",
       "             'dead': 621,\n",
       "             'element': 622,\n",
       "             'empire': 623,\n",
       "             'eye': 624,\n",
       "             'face': 625,\n",
       "             'featured': 626,\n",
       "             'federal': 627,\n",
       "             'follow': 628,\n",
       "             'formed': 629,\n",
       "             'golden': 630,\n",
       "             'got': 631,\n",
       "             'headquarters': 632,\n",
       "             'inside': 633,\n",
       "             'jimmy': 634,\n",
       "             'led': 635,\n",
       "             'living': 636,\n",
       "             'making': 637,\n",
       "             'male': 638,\n",
       "             'medical': 639,\n",
       "             'month': 640,\n",
       "             'motto': 641,\n",
       "             'museum': 642,\n",
       "             'nationality': 643,\n",
       "             'nine': 644,\n",
       "             'numbers': 645,\n",
       "             'off': 646,\n",
       "             'olympics': 647,\n",
       "             'opera': 648,\n",
       "             'oscar': 649,\n",
       "             'paid': 650,\n",
       "             'planet': 651,\n",
       "             'poet': 652,\n",
       "             'producer': 653,\n",
       "             'products': 654,\n",
       "             'put': 655,\n",
       "             'race': 656,\n",
       "             'roman': 657,\n",
       "             'rule': 658,\n",
       "             'security': 659,\n",
       "             'selling': 660,\n",
       "             'set': 661,\n",
       "             'setting': 662,\n",
       "             'side': 663,\n",
       "             'sound': 664,\n",
       "             'southern': 665,\n",
       "             'spoken': 666,\n",
       "             'stars': 667,\n",
       "             'students': 668,\n",
       "             'tall': 669,\n",
       "             'tallest': 670,\n",
       "             'ten': 671,\n",
       "             'this': 672,\n",
       "             'titled': 673,\n",
       "             'town': 674,\n",
       "             'union': 675,\n",
       "             'van': 676,\n",
       "             'video': 677,\n",
       "             'wars': 678,\n",
       "             'watch': 679,\n",
       "             'wear': 680,\n",
       "             'week': 681,\n",
       "             'weight': 682,\n",
       "             'wife': 683,\n",
       "             '!': 684,\n",
       "             '0': 685,\n",
       "             '11': 686,\n",
       "             '15': 687,\n",
       "             '1899': 688,\n",
       "             '1963': 689,\n",
       "             '1983': 690,\n",
       "             'aaron': 691,\n",
       "             'acid': 692,\n",
       "             'affect': 693,\n",
       "             'alphabet': 694,\n",
       "             'always': 695,\n",
       "             'army': 696,\n",
       "             'ask': 697,\n",
       "             'awarded': 698,\n",
       "             'based': 699,\n",
       "             'birthday': 700,\n",
       "             'books': 701,\n",
       "             'buffalo': 702,\n",
       "             'buy': 703,\n",
       "             'came': 704,\n",
       "             'career': 705,\n",
       "             'castle': 706,\n",
       "             'celebrated': 707,\n",
       "             'chicken': 708,\n",
       "             'cigarette': 709,\n",
       "             'clock': 710,\n",
       "             'columbia': 711,\n",
       "             'comics': 712,\n",
       "             'commercial': 713,\n",
       "             'corpus': 714,\n",
       "             'could': 715,\n",
       "             'cream': 716,\n",
       "             'create': 717,\n",
       "             'cup': 718,\n",
       "             'design': 719,\n",
       "             'diego': 720,\n",
       "             'early': 721,\n",
       "             'elected': 722,\n",
       "             'electric': 723,\n",
       "             'expression': 724,\n",
       "             'field': 725,\n",
       "             'fish': 726,\n",
       "             'florida': 727,\n",
       "             'followed': 728,\n",
       "             'friend': 729,\n",
       "             'gave': 730,\n",
       "             'german': 731,\n",
       "             'glass': 732,\n",
       "             'heart': 733,\n",
       "             'hero': 734,\n",
       "             'historical': 735,\n",
       "             'husband': 736,\n",
       "             'inches': 737,\n",
       "             'india': 738,\n",
       "             'ireland': 739,\n",
       "             'italian': 740,\n",
       "             'kid': 741,\n",
       "             'korea': 742,\n",
       "             'lady': 743,\n",
       "             'lakes': 744,\n",
       "             'least': 745,\n",
       "             'lyrics': 746,\n",
       "             'machines': 747,\n",
       "             'mark': 748,\n",
       "             'mayor': 749,\n",
       "             'mexico': 750,\n",
       "             'milk': 751,\n",
       "             'minimum': 752,\n",
       "             'miss': 753,\n",
       "             'mozambique': 754,\n",
       "             'must': 755,\n",
       "             'near': 756,\n",
       "             'nnp': 757,\n",
       "             'nobel': 758,\n",
       "             'online': 759,\n",
       "             'orange': 760,\n",
       "             'originally': 761,\n",
       "             'our': 762,\n",
       "             'paint': 763,\n",
       "             'party': 764,\n",
       "             'per': 765,\n",
       "             'players': 766,\n",
       "             'police': 767,\n",
       "             'program': 768,\n",
       "             'ray': 769,\n",
       "             'reason': 770,\n",
       "             'richest': 771,\n",
       "             'right': 772,\n",
       "             'salt': 773,\n",
       "             'schools': 774,\n",
       "             'secretary': 775,\n",
       "             'shakespeare': 776,\n",
       "             'she': 777,\n",
       "             'sign': 778,\n",
       "             'sleep': 779,\n",
       "             'small': 780,\n",
       "             'snow': 781,\n",
       "             'society': 782,\n",
       "             'spumante': 783,\n",
       "             'stock': 784,\n",
       "             'successful': 785,\n",
       "             'telephone': 786,\n",
       "             'thomas': 787,\n",
       "             'tokyo': 788,\n",
       "             'told': 789,\n",
       "             'trial': 790,\n",
       "             'vatican': 791,\n",
       "             'wage': 792,\n",
       "             'without': 793,\n",
       "             'written': 794,\n",
       "             '1991': 795,\n",
       "             '21': 796,\n",
       "             '27': 797,\n",
       "             '7': 798,\n",
       "             'album': 799,\n",
       "             'alley': 800,\n",
       "             'amount': 801,\n",
       "             'animated': 802,\n",
       "             'answers.com': 803,\n",
       "             'any': 804,\n",
       "             'atlantic': 805,\n",
       "             'automobile': 806,\n",
       "             'award': 807,\n",
       "             'bay': 808,\n",
       "             'bone': 809,\n",
       "             'border': 810,\n",
       "             'bottle': 811,\n",
       "             'bowling': 812,\n",
       "             'brain': 813,\n",
       "             'broadway': 814,\n",
       "             'bureau': 815,\n",
       "             'cancer': 816,\n",
       "             'caribbean': 817,\n",
       "             'charlie': 818,\n",
       "             'christian': 819,\n",
       "             'church': 820,\n",
       "             'close': 821,\n",
       "             'cocaine': 822,\n",
       "             'committee': 823,\n",
       "             'commonly': 824,\n",
       "             'complete': 825,\n",
       "             'conference': 826,\n",
       "             'contact': 827,\n",
       "             'contain': 828,\n",
       "             'contract': 829,\n",
       "             'control': 830,\n",
       "             'correct': 831,\n",
       "             'd.c.': 832,\n",
       "             'daily': 833,\n",
       "             'daughter': 834,\n",
       "             'dc': 835,\n",
       "             'declared': 836,\n",
       "             'degrees': 837,\n",
       "             'developed': 838,\n",
       "             'diamond': 839,\n",
       "             'discovered': 840,\n",
       "             'don': 841,\n",
       "             'drive': 842,\n",
       "             'drug': 843,\n",
       "             'education': 844,\n",
       "             'elements': 845,\n",
       "             'elephant': 846,\n",
       "             'emperor': 847,\n",
       "             'energy': 848,\n",
       "             'equal': 849,\n",
       "             'events': 850,\n",
       "             'fifth': 851,\n",
       "             'file': 852,\n",
       "             'films': 853,\n",
       "             'fox': 854,\n",
       "             'franklin': 855,\n",
       "             'free': 856,\n",
       "             'gate': 857,\n",
       "             'given': 858,\n",
       "             'going': 859,\n",
       "             'grow': 860,\n",
       "             'gulf': 861,\n",
       "             'harvey': 862,\n",
       "             'having': 863,\n",
       "             'himself': 864,\n",
       "             'hockey': 865,\n",
       "             'host': 866,\n",
       "             'inspired': 867,\n",
       "             'investigation': 868,\n",
       "             'iron': 869,\n",
       "             'italy': 870,\n",
       "             'jane': 871,\n",
       "             'jersey': 872,\n",
       "             'jewish': 873,\n",
       "             'johnny': 874,\n",
       "             'jude': 875,\n",
       "             'justice': 876,\n",
       "             'keep': 877,\n",
       "             'kids': 878,\n",
       "             'large': 879,\n",
       "             'leading': 880,\n",
       "             'leave': 881,\n",
       "             'lee': 882,\n",
       "             'literary': 883,\n",
       "             'madonna': 884,\n",
       "             'magic': 885,\n",
       "             'mary': 886,\n",
       "             'maurizio': 887,\n",
       "             'mccarren': 888,\n",
       "             'meant': 889,\n",
       "             'medicine': 890,\n",
       "             'members': 891,\n",
       "             'michael': 892,\n",
       "             'microsoft': 893,\n",
       "             'model': 894,\n",
       "             'mr.': 895,\n",
       "             'mrs.': 896,\n",
       "             'muppets': 897,\n",
       "             'murder': 898,\n",
       "             'mutombo': 899,\n",
       "             \"n't\": 900,\n",
       "             'nations': 901,\n",
       "             'native': 902,\n",
       "             'nfl': 903,\n",
       "             'occur': 904,\n",
       "             'order': 905,\n",
       "             'owns': 906,\n",
       "             'page': 907,\n",
       "             'painted': 908,\n",
       "             'painting': 909,\n",
       "             'pellegrin': 910,\n",
       "             'perfect': 911,\n",
       "             'period': 912,\n",
       "             'phone': 913,\n",
       "             'poem': 914,\n",
       "             'points': 915,\n",
       "             'pop': 916,\n",
       "             'presidential': 917,\n",
       "             'produces': 918,\n",
       "             'project': 919,\n",
       "             'read': 920,\n",
       "             'received': 921,\n",
       "             'reims': 922,\n",
       "             'religion': 923,\n",
       "             'remove': 924,\n",
       "             'represented': 925,\n",
       "             'research': 926,\n",
       "             'roosevelt': 927,\n",
       "             'salary': 928,\n",
       "             'same': 929,\n",
       "             'score': 930,\n",
       "             'seen': 931,\n",
       "             'serve': 932,\n",
       "             'sex': 933,\n",
       "             'silly': 934,\n",
       "             'silver': 935,\n",
       "             'simpsons': 936,\n",
       "             'single': 937,\n",
       "             'sister': 938,\n",
       "             'site': 939,\n",
       "             'sold': 940,\n",
       "             'spain': 941,\n",
       "             'spielberg': 942,\n",
       "             'submarine': 943,\n",
       "             'swimming': 944,\n",
       "             'tale': 945,\n",
       "             'taste': 946,\n",
       "             'temperature': 947,\n",
       "             'took': 948,\n",
       "             'treat': 949,\n",
       "             'turned': 950,\n",
       "             'twins': 951,\n",
       "             'universe': 952,\n",
       "             'usa': 953,\n",
       "             'using': 954,\n",
       "             'vegas': 955,\n",
       "             'vhs': 956,\n",
       "             'visit': 957,\n",
       "             'voice': 958,\n",
       "             'watergate': 959,\n",
       "             'ways': 960,\n",
       "             'wings': 961,\n",
       "             'working': 962,\n",
       "             'yankee': 963,\n",
       "             \"'ll\": 964,\n",
       "             '..': 965,\n",
       "             '000': 966,\n",
       "             '12': 967,\n",
       "             '13': 968,\n",
       "             '16th': 969,\n",
       "             '1939': 970,\n",
       "             '1960': 971,\n",
       "             '1965': 972,\n",
       "             '1967': 973,\n",
       "             '1969': 974,\n",
       "             '1980': 975,\n",
       "             '1994': 976,\n",
       "             '1998': 977,\n",
       "             '2000': 978,\n",
       "             'academy': 979,\n",
       "             'act': 980,\n",
       "             'ads': 981,\n",
       "             'adult': 982,\n",
       "             'advertise': 983,\n",
       "             'against': 984,\n",
       "             'ages': 985,\n",
       "             'ago': 986,\n",
       "             'airplane': 987,\n",
       "             'al': 988,\n",
       "             'along': 989,\n",
       "             'amendment': 990,\n",
       "             'appearance': 991,\n",
       "             'appeared': 992,\n",
       "             'arch': 993,\n",
       "             'arthur': 994,\n",
       "             'asia': 995,\n",
       "             'asked': 996,\n",
       "             'aspartame': 997,\n",
       "             'associated': 998,\n",
       "             'astronauts': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocab dictionaries\n",
    "text_field.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embeddings): Embedding(5002, 6)\n",
       "  (rnn): LSTM(6, 6, batch_first=True)\n",
       "  (linear): Linear(in_features=6, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_tokens, embedding_dim, rnn_dim, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_tokens, embedding_dim)\n",
    "        self.rnn = nn.LSTM(input_size = embedding_dim,\n",
    "                           hidden_size = rnn_dim, \n",
    "                           num_layers = num_layers,\n",
    "                           batch_first = True,\n",
    "                           bidirectional=False)\n",
    "        self.linear = nn.Linear(rnn_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embeddings(x)\n",
    "        rnn_output, rnn_hidden = self.rnn(emb) \n",
    "        x = rnn_output[:,-1,:]\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "model = RNN(word_count, 6, 6, 1, classes_count)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Objective function (and optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_decay = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train model (and test during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_iter = data.BucketIterator(train, \n",
    "                                 batch_size=batch_size, \n",
    "                                 sort_within_batch=True, \n",
    "                                 shuffle = True, \n",
    "                                 repeat = False)\n",
    "\n",
    "test_iter = data.BucketIterator(test, \n",
    "                          batch_size=30, \n",
    "                          sort_within_batch=True, \n",
    "                          shuffle = True, \n",
    "                          repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset variables \n",
    "accuracies = []\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "train_accuracy = 0\n",
    "step_count = 0\n",
    "max_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch  0\n",
      "Step:  0 Accuracy in test set: 0.22599999606609344\n",
      "Step:  100 Accuracy in test set: 0.1599999964237213\n",
      "Training epoch  1\n",
      "Step:  200 Accuracy in test set: 0.12399999797344208\n",
      "Step:  300 Accuracy in test set: 0.20399999618530273\n",
      "Training epoch  2\n",
      "Step:  400 Accuracy in test set: 0.19200000166893005\n",
      "Step:  500 Accuracy in test set: 0.20200000703334808\n",
      "Training epoch  3\n",
      "Step:  600 Accuracy in test set: 0.18000000715255737\n",
      "Training epoch  4\n",
      "Step:  700 Accuracy in test set: 0.20200000703334808\n",
      "Step:  800 Accuracy in test set: 0.20399999618530273\n",
      "Training epoch  5\n",
      "Step:  900 Accuracy in test set: 0.34599998593330383\n",
      "Step:  1000 Accuracy in test set: 0.2540000081062317\n",
      "Training epoch  6\n",
      "Step:  1100 Accuracy in test set: 0.3659999966621399\n",
      "Training epoch  7\n",
      "Step:  1200 Accuracy in test set: 0.3779999911785126\n",
      "Step:  1300 Accuracy in test set: 0.36800000071525574\n",
      "Training epoch  8\n",
      "Step:  1400 Accuracy in test set: 0.3700000047683716\n",
      "Step:  1500 Accuracy in test set: 0.41200000047683716\n",
      "Training epoch  9\n",
      "Step:  1600 Accuracy in test set: 0.4180000126361847\n",
      "Step:  1700 Accuracy in test set: 0.4259999990463257\n",
      "Training epoch  10\n",
      "Step:  1800 Accuracy in test set: 0.41999998688697815\n",
      "Training epoch  11\n",
      "Step:  1900 Accuracy in test set: 0.42800000309944153\n",
      "Step:  2000 Accuracy in test set: 0.43799999356269836\n",
      "Training epoch  12\n",
      "Step:  2100 Accuracy in test set: 0.4320000112056732\n",
      "Step:  2200 Accuracy in test set: 0.43799999356269836\n",
      "Training epoch  13\n",
      "Step:  2300 Accuracy in test set: 0.4480000138282776\n",
      "Training epoch  14\n",
      "Step:  2400 Accuracy in test set: 0.4359999895095825\n",
      "Step:  2500 Accuracy in test set: 0.43799999356269836\n",
      "Training epoch  15\n",
      "Step:  2600 Accuracy in test set: 0.43799999356269836\n",
      "Step:  2700 Accuracy in test set: 0.4480000138282776\n",
      "Training epoch  16\n",
      "Step:  2800 Accuracy in test set: 0.4440000057220459\n",
      "Step:  2900 Accuracy in test set: 0.4560000002384186\n",
      "Training epoch  17\n",
      "Step:  3000 Accuracy in test set: 0.43799999356269836\n",
      "Training epoch  18\n",
      "Step:  3100 Accuracy in test set: 0.4519999921321869\n",
      "Step:  3200 Accuracy in test set: 0.4399999976158142\n",
      "Training epoch  19\n",
      "Step:  3300 Accuracy in test set: 0.4519999921321869\n",
      "Step:  3400 Accuracy in test set: 0.4399999976158142\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "for i in range(num_epochs):\n",
    "    print('Training epoch ',i)\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:        \n",
    "\n",
    "        x_train = batch.text\n",
    "        y_train = batch.label\n",
    "\n",
    "        # Forward pass\n",
    "        y_model = model(x_train)\n",
    "\n",
    "        # Loss function\n",
    "        loss = loss_function(y_model, y_train)\n",
    "        losses_train.append(float(loss))\n",
    "\n",
    "        # Backward pass \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluation in test set\n",
    "\n",
    "        if step_count%100 == 0:\n",
    "\n",
    "            # Calculate model in test set by pieces\n",
    "            model.eval() # Set model to eval (if there is dropout, will set it to zero)\n",
    "            y_model_test_list = []\n",
    "            y_test_list = []\n",
    "            \n",
    "            for test_batch in test_iter:            \n",
    "                y_model_test_list.append(model(test_batch.text))            \n",
    "                y_test_list.append(test_batch.label)\n",
    "            model.train() # Set model to train (if there is dropout, will not be zero anymore)\n",
    "            test_iter.init_epoch()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = float( (torch.cat(y_model_test_list).max(dim=1)[1] == torch.cat(y_test_list)).float().mean() )\n",
    "            print('Step: ', step_count, 'Accuracy in test set:', accuracy)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        lr_decay.step()\n",
    "        step_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f121431a8d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Improve your RNN \n",
    "\n",
    "Improve your recurrent network:\n",
    "* Apply dropout between the LSTM and the linear layer\n",
    "* Add more complexity to the model (RNN layers, other layers)\n",
    "* Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embeddings): Embedding(5002, 50)\n",
       "  (rnn): LSTM(50, 20, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear): Linear(in_features=40, out_features=20, bias=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (linear2): Linear(in_features=20, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_tokens, embedding_dim, rnn_dim, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_tokens, embedding_dim)\n",
    "        self.rnn = nn.LSTM(input_size = embedding_dim,\n",
    "                           hidden_size = rnn_dim, \n",
    "                           num_layers = num_layers,\n",
    "                           batch_first = True,\n",
    "                           bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(2*rnn_dim, rnn_dim)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.linear2 = nn.Linear(rnn_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embeddings(x)\n",
    "        rnn_output, rnn_hidden = self.rnn(emb) \n",
    "        x = self.dropout(rnn_output)\n",
    "        x = self.linear(rnn_output[:,-1,:])\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = RNN(word_count, 50, 20, 3, classes_count)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_decay = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_iter = data.BucketIterator(train, \n",
    "                                 batch_size=batch_size, \n",
    "                                 sort_within_batch=True, \n",
    "                                 shuffle = True, \n",
    "                                 repeat = False)\n",
    "\n",
    "test_iter = data.BucketIterator(test, \n",
    "                          batch_size=30, \n",
    "                          sort_within_batch=True, \n",
    "                          shuffle = True, \n",
    "                          repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset variables \n",
    "accuracies = []\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "train_accuracy = 0\n",
    "step_count = 0\n",
    "max_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch  0\n",
      "Step:  0 Accuracy in test set: 0.16200000047683716\n",
      "Step:  100 Accuracy in test set: 0.18799999356269836\n",
      "Training epoch  1\n",
      "Step:  200 Accuracy in test set: 0.421999990940094\n",
      "Step:  300 Accuracy in test set: 0.414000004529953\n",
      "Training epoch  2\n",
      "Step:  400 Accuracy in test set: 0.4399999976158142\n",
      "Step:  500 Accuracy in test set: 0.5640000104904175\n",
      "Training epoch  3\n",
      "Step:  600 Accuracy in test set: 0.5619999766349792\n",
      "Training epoch  4\n",
      "Step:  700 Accuracy in test set: 0.578000009059906\n",
      "Step:  800 Accuracy in test set: 0.5600000023841858\n",
      "Training epoch  5\n",
      "Step:  900 Accuracy in test set: 0.578000009059906\n",
      "Step:  1000 Accuracy in test set: 0.6140000224113464\n",
      "Training epoch  6\n",
      "Step:  1100 Accuracy in test set: 0.5979999899864197\n",
      "Training epoch  7\n",
      "Step:  1200 Accuracy in test set: 0.6359999775886536\n",
      "Step:  1300 Accuracy in test set: 0.6420000195503235\n",
      "Training epoch  8\n",
      "Step:  1400 Accuracy in test set: 0.6420000195503235\n",
      "Step:  1500 Accuracy in test set: 0.6679999828338623\n",
      "Training epoch  9\n",
      "Step:  1600 Accuracy in test set: 0.7160000205039978\n",
      "Step:  1700 Accuracy in test set: 0.7419999837875366\n",
      "Training epoch  10\n",
      "Step:  1800 Accuracy in test set: 0.7440000176429749\n",
      "Training epoch  11\n",
      "Step:  1900 Accuracy in test set: 0.7459999918937683\n",
      "Step:  2000 Accuracy in test set: 0.765999972820282\n",
      "Training epoch  12\n",
      "Step:  2100 Accuracy in test set: 0.7620000243186951\n",
      "Step:  2200 Accuracy in test set: 0.7720000147819519\n",
      "Training epoch  13\n",
      "Step:  2300 Accuracy in test set: 0.7720000147819519\n",
      "Training epoch  14\n",
      "Step:  2400 Accuracy in test set: 0.7699999809265137\n",
      "Step:  2500 Accuracy in test set: 0.777999997138977\n",
      "Training epoch  15\n",
      "Step:  2600 Accuracy in test set: 0.7760000228881836\n",
      "Step:  2700 Accuracy in test set: 0.7720000147819519\n",
      "Training epoch  16\n",
      "Step:  2800 Accuracy in test set: 0.7820000052452087\n",
      "Step:  2900 Accuracy in test set: 0.7839999794960022\n",
      "Training epoch  17\n",
      "Step:  3000 Accuracy in test set: 0.7820000052452087\n",
      "Training epoch  18\n",
      "Step:  3100 Accuracy in test set: 0.777999997138977\n",
      "Step:  3200 Accuracy in test set: 0.7860000133514404\n",
      "Training epoch  19\n",
      "Step:  3300 Accuracy in test set: 0.7799999713897705\n",
      "Step:  3400 Accuracy in test set: 0.7799999713897705\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for i in range(num_epochs):\n",
    "    print('Training epoch ',i)\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:        \n",
    "\n",
    "        x_train = batch.text\n",
    "        y_train = batch.label\n",
    "\n",
    "        # Forward pass\n",
    "        y_model = model(x_train)\n",
    "\n",
    "        # Loss function\n",
    "        loss = loss_function(y_model, y_train)\n",
    "        losses_train.append(float(loss))\n",
    "\n",
    "        # Backward pass \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluation in test set\n",
    "\n",
    "        if step_count%100 == 0:\n",
    "\n",
    "            # Calculate model in test set by pieces\n",
    "            model.eval() # Set model to eval (if there is dropout, will set it to zero)\n",
    "            y_model_test_list = []\n",
    "            y_test_list = []\n",
    "            \n",
    "            for test_batch in test_iter:            \n",
    "                y_model_test_list.append(model(test_batch.text))            \n",
    "                y_test_list.append(test_batch.label)\n",
    "            model.train() # Set model to train (if there is dropout, will not be zero anymore)\n",
    "            test_iter.init_epoch()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = float( (torch.cat(y_model_test_list).max(dim=1)[1] == torch.cat(y_test_list)).float().mean() )\n",
    "            print('Step: ', step_count, 'Accuracy in test set:', accuracy)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        lr_decay.step()\n",
    "        step_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
