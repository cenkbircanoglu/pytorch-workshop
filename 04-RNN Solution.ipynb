{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to build a model to classify text, using the TREC-6 dataset.\n",
    "\n",
    "The TREC-6 dataset consist on a set of 5,952 questions written in English, classified in the following categories, depending on the answer:\n",
    "\n",
    "* HUM: Human\n",
    "* DESC: Description\n",
    "* ABBR: Abbreviation\n",
    "* LOC: Location\n",
    "* NUM: Number\n",
    "* ENTY: Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
      "\u001b[K    100% |################################| 61kB 25.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting spacy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K    100% |################################| 10.4MB 4.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (1.13.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (2.22.0)\n",
      "Collecting tqdm (from torchtext)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/b0/6d63e33dbf5935dccd334ee2b83cc4d3828817de6faaa3a3f7f5b8cc5141/tqdm-4.40.1-py2.py3-none-any.whl (55kB)\n",
      "\u001b[K    100% |################################| 61kB 33.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (1.3.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from torchtext) (1.17.4)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting srsly<1.1.0,>=0.1.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/fb/34136c7b2ad04d4472dd9ea86536f5e9fb71fb0eb78edc8dad76a3f9edf2/srsly-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (185kB)\n",
      "\u001b[K    100% |################################| 194kB 43.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/d5/46ff975f0d7d055cf95557b944fd5d29d9dfb37a4341038e070f212b24fe/catalogue-0.0.8-py2.py3-none-any.whl\n",
      "Collecting wasabi<1.1.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/ef/e8266e158ed32bf5f723fac862b6518833d0b53ca183165a8718f212c0d5/wasabi-0.4.2-py3-none-any.whl\n",
      "Collecting plac<1.2.0,>=0.9.6 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy) (40.6.2)\n",
      "Collecting thinc<7.4.0,>=7.3.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |################################| 2.2MB 20.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
      "\u001b[K    100% |################################| 122kB 43.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.5.0,>=0.4.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K    100% |################################| 3.7MB 12.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests->torchtext) (1.25.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (8.0.2)\n",
      "Installing collected packages: tqdm, torchtext, cymem, srsly, catalogue, wasabi, plac, murmurhash, preshed, blis, thinc, spacy\n",
      "Successfully installed blis-0.4.1 catalogue-0.0.8 cymem-2.0.3 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.2.3 srsly-0.2.0 thinc-7.3.1 torchtext-0.4.0 tqdm-4.40.1 wasabi-0.4.2\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0MB)\n",
      "\u001b[K    100% |################################| 12.0MB 1.3MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (40.6.2)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.17.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.2.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.40.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/ubuntu/.pyenv/versions/3.6.9/envs/learn-pytorch/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (8.0.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-sm-2.2.5\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m[+] Linking successful\u001b[0m\n",
      "/home/ubuntu/.pyenv/versions/learn-pytorch/lib/python3.6/site-packages/en_core_web_sm\n",
      "-->\n",
      "/home/ubuntu/.pyenv/versions/learn-pytorch/lib/python3.6/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "# The following lines will install the torchtext and spacy libraries, \n",
    "# used to prepare text datasets for models in PyTorch.\n",
    "\n",
    "!pip install torchtext spacy\n",
    "#!conda install -c conda-forge spacy -y\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading train_5500.label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_5500.label: 100%|██████████| 336k/336k [00:00<00:00, 931kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading TREC_10.label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TREC_10.label: 100%|██████████| 23.4k/23.4k [00:00<00:00, 278kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 5452\n",
      "Test length: 500\n"
     ]
    }
   ],
   "source": [
    "# Get datasets\n",
    "text_field = data.Field(lower=True, batch_first=True, tokenize='spacy')\n",
    "label_field = data.Field(sequential=False, unk_token = None)\n",
    "train, test = datasets.TREC.splits(text_field, label_field)\n",
    "\n",
    "print('Train length:',str(len(train)))\n",
    "print('Test length:',str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who is olive oyl 's brother ? HUM\n",
      "who is king in alley oop 's home of moo ? HUM\n",
      "what 's the only work by michelangelo that bears his signature ? ENTY\n",
      "what was the eighth day following the nones in each month of the roman calendar called ? ENTY\n",
      "how many meters are in a mile ? NUM\n",
      "what hide - and - seek game is played around a tin can ? ENTY\n",
      "how do you ask questions ? DESC\n",
      "what substance did joseph priestley name for its ability to erase pencil marks ? ENTY\n",
      "what 's the second - biggest - selling magazine in america ? ENTY\n",
      "what are vermicilli , rigati , zitoni , and tubetti ? DESC\n"
     ]
    }
   ],
   "source": [
    "# Show some examples\n",
    "\n",
    "for i in range(10):\n",
    "    random_index = random.randint(0,len(train))\n",
    "    print(' '.join(train.examples[random_index].text), train.examples[random_index].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 5002\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "vocab_length = 5000\n",
    "text_field.build_vocab(train, max_size=vocab_length)\n",
    "label_field.build_vocab(train)\n",
    "\n",
    "classes_count = len(label_field.vocab)\n",
    "word_count = len(text_field.vocab)\n",
    "print('Vocabulary length:', word_count)\n",
    "print('Number of classes:', classes_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7fcaed805630>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             '?': 2,\n",
       "             'the': 3,\n",
       "             'what': 4,\n",
       "             'is': 5,\n",
       "             'of': 6,\n",
       "             'in': 7,\n",
       "             'a': 8,\n",
       "             '`': 9,\n",
       "             'how': 10,\n",
       "             \"'s\": 11,\n",
       "             'was': 12,\n",
       "             'to': 13,\n",
       "             'who': 14,\n",
       "             ',': 15,\n",
       "             'are': 16,\n",
       "             'for': 17,\n",
       "             'and': 18,\n",
       "             \"''\": 19,\n",
       "             'does': 20,\n",
       "             'did': 21,\n",
       "             '-': 22,\n",
       "             'do': 23,\n",
       "             'many': 24,\n",
       "             'name': 25,\n",
       "             'on': 26,\n",
       "             'where': 27,\n",
       "             'i': 28,\n",
       "             'first': 29,\n",
       "             'you': 30,\n",
       "             'can': 31,\n",
       "             'when': 32,\n",
       "             'world': 33,\n",
       "             'from': 34,\n",
       "             'which': 35,\n",
       "             'by': 36,\n",
       "             'that': 37,\n",
       "             'u.s.': 38,\n",
       "             'country': 39,\n",
       "             'most': 40,\n",
       "             'an': 41,\n",
       "             'as': 42,\n",
       "             'with': 43,\n",
       "             'have': 44,\n",
       "             'city': 45,\n",
       "             '.': 46,\n",
       "             'has': 47,\n",
       "             'why': 48,\n",
       "             \"'\": 49,\n",
       "             'it': 50,\n",
       "             'there': 51,\n",
       "             'be': 52,\n",
       "             'people': 53,\n",
       "             'get': 54,\n",
       "             'at': 55,\n",
       "             'were': 56,\n",
       "             'find': 57,\n",
       "             'called': 58,\n",
       "             'his': 59,\n",
       "             'year': 60,\n",
       "             'state': 61,\n",
       "             'president': 62,\n",
       "             'american': 63,\n",
       "             'two': 64,\n",
       "             'largest': 65,\n",
       "             'mean': 66,\n",
       "             'war': 67,\n",
       "             'fear': 68,\n",
       "             'made': 69,\n",
       "             'new': 70,\n",
       "             'much': 71,\n",
       "             'long': 72,\n",
       "             'between': 73,\n",
       "             ':': 74,\n",
       "             'its': 75,\n",
       "             'origin': 76,\n",
       "             'used': 77,\n",
       "             'word': 78,\n",
       "             'about': 79,\n",
       "             'company': 80,\n",
       "             'known': 81,\n",
       "             'movie': 82,\n",
       "             'tv': 83,\n",
       "             'film': 84,\n",
       "             'kind': 85,\n",
       "             'one': 86,\n",
       "             'all': 87,\n",
       "             'famous': 88,\n",
       "             'best': 89,\n",
       "             'day': 90,\n",
       "             'or': 91,\n",
       "             'make': 92,\n",
       "             'take': 93,\n",
       "             'game': 94,\n",
       "             'he': 95,\n",
       "             'stand': 96,\n",
       "             'time': 97,\n",
       "             'up': 98,\n",
       "             'your': 99,\n",
       "             'live': 100,\n",
       "             'invented': 101,\n",
       "             'man': 102,\n",
       "             'book': 103,\n",
       "             'come': 104,\n",
       "             'only': 105,\n",
       "             'color': 106,\n",
       "             'john': 107,\n",
       "             'my': 108,\n",
       "             'not': 109,\n",
       "             'into': 110,\n",
       "             'old': 111,\n",
       "             'out': 112,\n",
       "             'play': 113,\n",
       "             'show': 114,\n",
       "             'term': 115,\n",
       "             'their': 116,\n",
       "             'wrote': 117,\n",
       "             'states': 118,\n",
       "             'countries': 119,\n",
       "             'last': 120,\n",
       "             'star': 121,\n",
       "             'america': 122,\n",
       "             'four': 123,\n",
       "             'home': 124,\n",
       "             'if': 125,\n",
       "             'named': 126,\n",
       "             'south': 127,\n",
       "             'won': 128,\n",
       "             'call': 129,\n",
       "             'highest': 130,\n",
       "             'team': 131,\n",
       "             'baseball': 132,\n",
       "             'character': 133,\n",
       "             'difference': 134,\n",
       "             'had': 135,\n",
       "             'king': 136,\n",
       "             'number': 137,\n",
       "             'river': 138,\n",
       "             'after': 139,\n",
       "             'english': 140,\n",
       "             'use': 141,\n",
       "             'born': 142,\n",
       "             'three': 143,\n",
       "             'died': 144,\n",
       "             'information': 145,\n",
       "             'novel': 146,\n",
       "             'played': 147,\n",
       "             'said': 148,\n",
       "             'some': 149,\n",
       "             'song': 150,\n",
       "             'work': 151,\n",
       "             'been': 152,\n",
       "             'black': 153,\n",
       "             'united': 154,\n",
       "             'actor': 155,\n",
       "             'average': 156,\n",
       "             'become': 157,\n",
       "             'capital': 158,\n",
       "             'college': 159,\n",
       "             'common': 160,\n",
       "             'dog': 161,\n",
       "             'say': 162,\n",
       "             'us': 163,\n",
       "             'will': 164,\n",
       "             'years': 165,\n",
       "             '1': 166,\n",
       "             'actress': 167,\n",
       "             'body': 168,\n",
       "             'computer': 169,\n",
       "             'earth': 170,\n",
       "             'go': 171,\n",
       "             'names': 172,\n",
       "             'population': 173,\n",
       "             'second': 174,\n",
       "             'water': 175,\n",
       "             'california': 176,\n",
       "             'drink': 177,\n",
       "             'food': 178,\n",
       "             'group': 179,\n",
       "             'located': 180,\n",
       "             'mountain': 181,\n",
       "             'sport': 182,\n",
       "             't': 183,\n",
       "             'they': 184,\n",
       "             'woman': 185,\n",
       "             'would': 186,\n",
       "             'die': 187,\n",
       "             'during': 188,\n",
       "             'good': 189,\n",
       "             'island': 190,\n",
       "             'like': 191,\n",
       "             'north': 192,\n",
       "             'space': 193,\n",
       "             'than': 194,\n",
       "             'times': 195,\n",
       "             'top': 196,\n",
       "             'york': 197,\n",
       "             'animal': 198,\n",
       "             'killed': 199,\n",
       "             'longest': 200,\n",
       "             'money': 201,\n",
       "             'school': 202,\n",
       "             'sea': 203,\n",
       "             'great': 204,\n",
       "             'history': 205,\n",
       "             'law': 206,\n",
       "             'more': 207,\n",
       "             'over': 208,\n",
       "             'part': 209,\n",
       "             'popular': 210,\n",
       "             'portrayed': 211,\n",
       "             'through': 212,\n",
       "             'university': 213,\n",
       "             'big': 214,\n",
       "             'different': 215,\n",
       "             'her': 216,\n",
       "             'language': 217,\n",
       "             'major': 218,\n",
       "             'makes': 219,\n",
       "             'person': 220,\n",
       "             'red': 221,\n",
       "             'should': 222,\n",
       "             'way': 223,\n",
       "             'car': 224,\n",
       "             'cities': 225,\n",
       "             'date': 226,\n",
       "             'each': 227,\n",
       "             'five': 228,\n",
       "             'general': 229,\n",
       "             'horse': 230,\n",
       "             'internet': 231,\n",
       "             'line': 232,\n",
       "             'meaning': 233,\n",
       "             'national': 234,\n",
       "             'title': 235,\n",
       "             'west': 236,\n",
       "             'address': 237,\n",
       "             'became': 238,\n",
       "             'charles': 239,\n",
       "             'contains': 240,\n",
       "             'cost': 241,\n",
       "             'craft': 242,\n",
       "             'created': 243,\n",
       "             'french': 244,\n",
       "             'international': 245,\n",
       "             'leader': 246,\n",
       "             'life': 247,\n",
       "             'miles': 248,\n",
       "             'russian': 249,\n",
       "             'so': 250,\n",
       "             'write': 251,\n",
       "             'battle': 252,\n",
       "             'biggest': 253,\n",
       "             'built': 254,\n",
       "             'causes': 255,\n",
       "             'letter': 256,\n",
       "             'me': 257,\n",
       "             'place': 258,\n",
       "             'randy': 259,\n",
       "             'white': 260,\n",
       "             'whose': 261,\n",
       "             'abbreviation': 262,\n",
       "             'airport': 263,\n",
       "             'bridge': 264,\n",
       "             'century': 265,\n",
       "             'features': 266,\n",
       "             'feet': 267,\n",
       "             'form': 268,\n",
       "             'found': 269,\n",
       "             'games': 270,\n",
       "             'ii': 271,\n",
       "             'little': 272,\n",
       "             'moon': 273,\n",
       "             'power': 274,\n",
       "             'queen': 275,\n",
       "             'seven': 276,\n",
       "             'system': 277,\n",
       "             '5': 278,\n",
       "             'air': 279,\n",
       "             'baby': 280,\n",
       "             'begin': 281,\n",
       "             'boasts': 282,\n",
       "             'british': 283,\n",
       "             'children': 284,\n",
       "             'colors': 285,\n",
       "             'comic': 286,\n",
       "             'death': 287,\n",
       "             'e': 288,\n",
       "             'eat': 289,\n",
       "             'england': 290,\n",
       "             'following': 291,\n",
       "             'george': 292,\n",
       "             'germany': 293,\n",
       "             'high': 294,\n",
       "             'human': 295,\n",
       "             'james': 296,\n",
       "             'kennedy': 297,\n",
       "             'league': 298,\n",
       "             'london': 299,\n",
       "             'love': 300,\n",
       "             'men': 301,\n",
       "             'nickname': 302,\n",
       "             'nixon': 303,\n",
       "             'no': 304,\n",
       "             'office': 305,\n",
       "             'park': 306,\n",
       "             'player': 307,\n",
       "             'san': 308,\n",
       "             'someone': 309,\n",
       "             'spanish': 310,\n",
       "             'type': 311,\n",
       "             '2': 312,\n",
       "             'area': 313,\n",
       "             'blood': 314,\n",
       "             'bowl': 315,\n",
       "             'disease': 316,\n",
       "             'european': 317,\n",
       "             'held': 318,\n",
       "             'hit': 319,\n",
       "             'hole': 320,\n",
       "             'house': 321,\n",
       "             'islands': 322,\n",
       "             'japanese': 323,\n",
       "             'letters': 324,\n",
       "             'may': 325,\n",
       "             'mother': 326,\n",
       "             'nn': 327,\n",
       "             'product': 328,\n",
       "             'rate': 329,\n",
       "             'real': 330,\n",
       "             'soft': 331,\n",
       "             'television': 332,\n",
       "             'washington': 333,\n",
       "             'animals': 334,\n",
       "             'before': 335,\n",
       "             'bill': 336,\n",
       "             'business': 337,\n",
       "             'center': 338,\n",
       "             'chemical': 339,\n",
       "             'father': 340,\n",
       "             'female': 341,\n",
       "             'happened': 342,\n",
       "             'know': 343,\n",
       "             'lawyer': 344,\n",
       "             'married': 345,\n",
       "             'member': 346,\n",
       "             'o': 347,\n",
       "             'ocean': 348,\n",
       "             'st.': 349,\n",
       "             'super': 350,\n",
       "             'william': 351,\n",
       "             'words': 352,\n",
       "             '&': 353,\n",
       "             'age': 354,\n",
       "             'building': 355,\n",
       "             'christmas': 356,\n",
       "             'definition': 357,\n",
       "             'ever': 358,\n",
       "             'hitler': 359,\n",
       "             'ice': 360,\n",
       "             'lives': 361,\n",
       "             'music': 362,\n",
       "             'newspaper': 363,\n",
       "             'once': 364,\n",
       "             'runs': 365,\n",
       "             'series': 366,\n",
       "             'served': 367,\n",
       "             'singing': 368,\n",
       "             'soldiers': 369,\n",
       "             'tree': 370,\n",
       "             'whom': 371,\n",
       "             'win': 372,\n",
       "             '$': 373,\n",
       "             'africa': 374,\n",
       "             'another': 375,\n",
       "             'around': 376,\n",
       "             'ball': 377,\n",
       "             'beer': 378,\n",
       "             'being': 379,\n",
       "             'birth': 380,\n",
       "             'boy': 381,\n",
       "             'canada': 382,\n",
       "             'civil': 383,\n",
       "             'cnn': 384,\n",
       "             'code': 385,\n",
       "             'county': 386,\n",
       "             'dick': 387,\n",
       "             'end': 388,\n",
       "             'f.': 389,\n",
       "             'far': 390,\n",
       "             'girl': 391,\n",
       "             'greek': 392,\n",
       "             'indians': 393,\n",
       "             'jack': 394,\n",
       "             'main': 395,\n",
       "             'minister': 396,\n",
       "             'mississippi': 397,\n",
       "             'night': 398,\n",
       "             'oldest': 399,\n",
       "             'original': 400,\n",
       "             'other': 401,\n",
       "             'prime': 402,\n",
       "             'prize': 403,\n",
       "             'radio': 404,\n",
       "             'rock': 405,\n",
       "             'ship': 406,\n",
       "             'singer': 407,\n",
       "             'six': 408,\n",
       "             'sports': 409,\n",
       "             'store': 410,\n",
       "             'tell': 411,\n",
       "             'them': 412,\n",
       "             'travel': 413,\n",
       "             'tuberculosis': 414,\n",
       "             'we': 415,\n",
       "             'web': 416,\n",
       "             '10': 417,\n",
       "             '3': 418,\n",
       "             'art': 419,\n",
       "             'back': 420,\n",
       "             'basketball': 421,\n",
       "             'bible': 422,\n",
       "             'board': 423,\n",
       "             'but': 424,\n",
       "             'card': 425,\n",
       "             'cartoon': 426,\n",
       "             'china': 427,\n",
       "             'claim': 428,\n",
       "             'cold': 429,\n",
       "             'comedian': 430,\n",
       "             'cross': 431,\n",
       "             'department': 432,\n",
       "             'down': 433,\n",
       "             'east': 434,\n",
       "             'fame': 435,\n",
       "             'famed': 436,\n",
       "             'fast': 437,\n",
       "             'flag': 438,\n",
       "             'football': 439,\n",
       "             'former': 440,\n",
       "             'founded': 441,\n",
       "             'god': 442,\n",
       "             'gold': 443,\n",
       "             'indian': 444,\n",
       "             'introduced': 445,\n",
       "             'kentucky': 446,\n",
       "             'lake': 447,\n",
       "             'marvel': 448,\n",
       "             'musical': 449,\n",
       "             'never': 450,\n",
       "             'now': 451,\n",
       "             'olympic': 452,\n",
       "             'originate': 453,\n",
       "             'percentage': 454,\n",
       "             'pope': 455,\n",
       "             'produce': 456,\n",
       "             'richard': 457,\n",
       "             'role': 458,\n",
       "             'saw': 459,\n",
       "             'see': 460,\n",
       "             'size': 461,\n",
       "             'son': 462,\n",
       "             'starred': 463,\n",
       "             'story': 464,\n",
       "             'tax': 465,\n",
       "             'then': 466,\n",
       "             'thing': 467,\n",
       "             'while': 468,\n",
       "             '1984': 469,\n",
       "             'americans': 470,\n",
       "             'appear': 471,\n",
       "             'author': 472,\n",
       "             'bear': 473,\n",
       "             'berlin': 474,\n",
       "             'blue': 475,\n",
       "             'brothers': 476,\n",
       "             'cards': 477,\n",
       "             'caused': 478,\n",
       "             'child': 479,\n",
       "             'chinese': 480,\n",
       "             'director': 481,\n",
       "             'dubbed': 482,\n",
       "             'europe': 483,\n",
       "             'every': 484,\n",
       "             'family': 485,\n",
       "             'fastest': 486,\n",
       "             'favorite': 487,\n",
       "             'fought': 488,\n",
       "             'full': 489,\n",
       "             'give': 490,\n",
       "             'golf': 491,\n",
       "             'hair': 492,\n",
       "             'head': 493,\n",
       "             'income': 494,\n",
       "             'japan': 495,\n",
       "             'latin': 496,\n",
       "             'list': 497,\n",
       "             'lived': 498,\n",
       "             'look': 499,\n",
       "             'los': 500,\n",
       "             'mile': 501,\n",
       "             'mount': 502,\n",
       "             'need': 503,\n",
       "             'organization': 504,\n",
       "             'own': 505,\n",
       "             'record': 506,\n",
       "             'shot': 507,\n",
       "             'sioux': 508,\n",
       "             'sometimes': 509,\n",
       "             'soviet': 510,\n",
       "             'species': 511,\n",
       "             'start': 512,\n",
       "             'started': 513,\n",
       "             'steven': 514,\n",
       "             'street': 515,\n",
       "             'strip': 516,\n",
       "             'symbol': 517,\n",
       "             'texas': 518,\n",
       "             'tom': 519,\n",
       "             'under': 520,\n",
       "             'vietnam': 521,\n",
       "             'website': 522,\n",
       "             'went': 523,\n",
       "             'wine': 524,\n",
       "             'women': 525,\n",
       "             'worth': 526,\n",
       "             '6': 527,\n",
       "             '8': 528,\n",
       "             'african': 529,\n",
       "             'angeles': 530,\n",
       "             'asian': 531,\n",
       "             'australia': 532,\n",
       "             'band': 533,\n",
       "             'beach': 534,\n",
       "             'because': 535,\n",
       "             'believe': 536,\n",
       "             'birds': 537,\n",
       "             'boxing': 538,\n",
       "             'brand': 539,\n",
       "             'captain': 540,\n",
       "             'characters': 541,\n",
       "             'chicago': 542,\n",
       "             'continent': 543,\n",
       "             'court': 544,\n",
       "             'days': 545,\n",
       "             'de': 546,\n",
       "             'desert': 547,\n",
       "             'eggs': 548,\n",
       "             'el': 549,\n",
       "             'eyes': 550,\n",
       "             'fire': 551,\n",
       "             'flight': 552,\n",
       "             'fly': 553,\n",
       "             'france': 554,\n",
       "             'gas': 555,\n",
       "             'gould': 556,\n",
       "             'government': 557,\n",
       "             'greatest': 558,\n",
       "             'green': 559,\n",
       "             'hand': 560,\n",
       "             'hands': 561,\n",
       "             'henry': 562,\n",
       "             'instrument': 563,\n",
       "             'jackson': 564,\n",
       "             'jaws': 565,\n",
       "             'languages': 566,\n",
       "             'left': 567,\n",
       "             'light': 568,\n",
       "             'lost': 569,\n",
       "             'magazine': 570,\n",
       "             'mail': 571,\n",
       "             'march': 572,\n",
       "             'massachusetts': 573,\n",
       "             'middle': 574,\n",
       "             'million': 575,\n",
       "             'monopoly': 576,\n",
       "             'months': 577,\n",
       "             'nuclear': 578,\n",
       "             'often': 579,\n",
       "             'oil': 580,\n",
       "             'paper': 581,\n",
       "             'peter': 582,\n",
       "             'plant': 583,\n",
       "             'plays': 584,\n",
       "             'point': 585,\n",
       "             'presidents': 586,\n",
       "             'prince': 587,\n",
       "             'produced': 588,\n",
       "             'rights': 589,\n",
       "             'run': 590,\n",
       "             'shea': 591,\n",
       "             'square': 592,\n",
       "             'stop': 593,\n",
       "             'sun': 594,\n",
       "             'tennis': 595,\n",
       "             'thatcher': 596,\n",
       "             'types': 597,\n",
       "             'wall': 598,\n",
       "             'winter': 599,\n",
       "             'writer': 600,\n",
       "             'aids': 601,\n",
       "             'alaska': 602,\n",
       "             'allowed': 603,\n",
       "             'also': 604,\n",
       "             'artist': 605,\n",
       "             'assassinated': 606,\n",
       "             'balls': 607,\n",
       "             'bond': 608,\n",
       "             'brown': 609,\n",
       "             'build': 610,\n",
       "             'buried': 611,\n",
       "             'cars': 612,\n",
       "             'cat': 613,\n",
       "             'claimed': 614,\n",
       "             'comes': 615,\n",
       "             'companies': 616,\n",
       "             'considered': 617,\n",
       "             'cover': 618,\n",
       "             'cowboy': 619,\n",
       "             'current': 620,\n",
       "             'dead': 621,\n",
       "             'element': 622,\n",
       "             'empire': 623,\n",
       "             'eye': 624,\n",
       "             'face': 625,\n",
       "             'featured': 626,\n",
       "             'federal': 627,\n",
       "             'follow': 628,\n",
       "             'formed': 629,\n",
       "             'golden': 630,\n",
       "             'got': 631,\n",
       "             'headquarters': 632,\n",
       "             'inside': 633,\n",
       "             'jimmy': 634,\n",
       "             'led': 635,\n",
       "             'living': 636,\n",
       "             'making': 637,\n",
       "             'male': 638,\n",
       "             'medical': 639,\n",
       "             'month': 640,\n",
       "             'motto': 641,\n",
       "             'museum': 642,\n",
       "             'nationality': 643,\n",
       "             'nine': 644,\n",
       "             'numbers': 645,\n",
       "             'off': 646,\n",
       "             'olympics': 647,\n",
       "             'opera': 648,\n",
       "             'oscar': 649,\n",
       "             'paid': 650,\n",
       "             'planet': 651,\n",
       "             'poet': 652,\n",
       "             'producer': 653,\n",
       "             'products': 654,\n",
       "             'put': 655,\n",
       "             'race': 656,\n",
       "             'roman': 657,\n",
       "             'rule': 658,\n",
       "             'security': 659,\n",
       "             'selling': 660,\n",
       "             'set': 661,\n",
       "             'setting': 662,\n",
       "             'side': 663,\n",
       "             'sound': 664,\n",
       "             'southern': 665,\n",
       "             'spoken': 666,\n",
       "             'stars': 667,\n",
       "             'students': 668,\n",
       "             'tall': 669,\n",
       "             'tallest': 670,\n",
       "             'ten': 671,\n",
       "             'this': 672,\n",
       "             'titled': 673,\n",
       "             'town': 674,\n",
       "             'union': 675,\n",
       "             'van': 676,\n",
       "             'video': 677,\n",
       "             'wars': 678,\n",
       "             'watch': 679,\n",
       "             'wear': 680,\n",
       "             'week': 681,\n",
       "             'weight': 682,\n",
       "             'wife': 683,\n",
       "             '!': 684,\n",
       "             '0': 685,\n",
       "             '11': 686,\n",
       "             '15': 687,\n",
       "             '1899': 688,\n",
       "             '1963': 689,\n",
       "             '1983': 690,\n",
       "             'aaron': 691,\n",
       "             'acid': 692,\n",
       "             'affect': 693,\n",
       "             'alphabet': 694,\n",
       "             'always': 695,\n",
       "             'army': 696,\n",
       "             'ask': 697,\n",
       "             'awarded': 698,\n",
       "             'based': 699,\n",
       "             'birthday': 700,\n",
       "             'books': 701,\n",
       "             'buffalo': 702,\n",
       "             'buy': 703,\n",
       "             'came': 704,\n",
       "             'career': 705,\n",
       "             'castle': 706,\n",
       "             'celebrated': 707,\n",
       "             'chicken': 708,\n",
       "             'cigarette': 709,\n",
       "             'clock': 710,\n",
       "             'columbia': 711,\n",
       "             'comics': 712,\n",
       "             'commercial': 713,\n",
       "             'corpus': 714,\n",
       "             'could': 715,\n",
       "             'cream': 716,\n",
       "             'create': 717,\n",
       "             'cup': 718,\n",
       "             'design': 719,\n",
       "             'diego': 720,\n",
       "             'early': 721,\n",
       "             'elected': 722,\n",
       "             'electric': 723,\n",
       "             'expression': 724,\n",
       "             'field': 725,\n",
       "             'fish': 726,\n",
       "             'florida': 727,\n",
       "             'followed': 728,\n",
       "             'friend': 729,\n",
       "             'gave': 730,\n",
       "             'german': 731,\n",
       "             'glass': 732,\n",
       "             'heart': 733,\n",
       "             'hero': 734,\n",
       "             'historical': 735,\n",
       "             'husband': 736,\n",
       "             'inches': 737,\n",
       "             'india': 738,\n",
       "             'ireland': 739,\n",
       "             'italian': 740,\n",
       "             'kid': 741,\n",
       "             'korea': 742,\n",
       "             'lady': 743,\n",
       "             'lakes': 744,\n",
       "             'least': 745,\n",
       "             'lyrics': 746,\n",
       "             'machines': 747,\n",
       "             'mark': 748,\n",
       "             'mayor': 749,\n",
       "             'mexico': 750,\n",
       "             'milk': 751,\n",
       "             'minimum': 752,\n",
       "             'miss': 753,\n",
       "             'mozambique': 754,\n",
       "             'must': 755,\n",
       "             'near': 756,\n",
       "             'nnp': 757,\n",
       "             'nobel': 758,\n",
       "             'online': 759,\n",
       "             'orange': 760,\n",
       "             'originally': 761,\n",
       "             'our': 762,\n",
       "             'paint': 763,\n",
       "             'party': 764,\n",
       "             'per': 765,\n",
       "             'players': 766,\n",
       "             'police': 767,\n",
       "             'program': 768,\n",
       "             'ray': 769,\n",
       "             'reason': 770,\n",
       "             'richest': 771,\n",
       "             'right': 772,\n",
       "             'salt': 773,\n",
       "             'schools': 774,\n",
       "             'secretary': 775,\n",
       "             'shakespeare': 776,\n",
       "             'she': 777,\n",
       "             'sign': 778,\n",
       "             'sleep': 779,\n",
       "             'small': 780,\n",
       "             'snow': 781,\n",
       "             'society': 782,\n",
       "             'spumante': 783,\n",
       "             'stock': 784,\n",
       "             'successful': 785,\n",
       "             'telephone': 786,\n",
       "             'thomas': 787,\n",
       "             'tokyo': 788,\n",
       "             'told': 789,\n",
       "             'trial': 790,\n",
       "             'vatican': 791,\n",
       "             'wage': 792,\n",
       "             'without': 793,\n",
       "             'written': 794,\n",
       "             '1991': 795,\n",
       "             '21': 796,\n",
       "             '27': 797,\n",
       "             '7': 798,\n",
       "             'album': 799,\n",
       "             'alley': 800,\n",
       "             'amount': 801,\n",
       "             'animated': 802,\n",
       "             'answers.com': 803,\n",
       "             'any': 804,\n",
       "             'atlantic': 805,\n",
       "             'automobile': 806,\n",
       "             'award': 807,\n",
       "             'bay': 808,\n",
       "             'bone': 809,\n",
       "             'border': 810,\n",
       "             'bottle': 811,\n",
       "             'bowling': 812,\n",
       "             'brain': 813,\n",
       "             'broadway': 814,\n",
       "             'bureau': 815,\n",
       "             'cancer': 816,\n",
       "             'caribbean': 817,\n",
       "             'charlie': 818,\n",
       "             'christian': 819,\n",
       "             'church': 820,\n",
       "             'close': 821,\n",
       "             'cocaine': 822,\n",
       "             'committee': 823,\n",
       "             'commonly': 824,\n",
       "             'complete': 825,\n",
       "             'conference': 826,\n",
       "             'contact': 827,\n",
       "             'contain': 828,\n",
       "             'contract': 829,\n",
       "             'control': 830,\n",
       "             'correct': 831,\n",
       "             'd.c.': 832,\n",
       "             'daily': 833,\n",
       "             'daughter': 834,\n",
       "             'dc': 835,\n",
       "             'declared': 836,\n",
       "             'degrees': 837,\n",
       "             'developed': 838,\n",
       "             'diamond': 839,\n",
       "             'discovered': 840,\n",
       "             'don': 841,\n",
       "             'drive': 842,\n",
       "             'drug': 843,\n",
       "             'education': 844,\n",
       "             'elements': 845,\n",
       "             'elephant': 846,\n",
       "             'emperor': 847,\n",
       "             'energy': 848,\n",
       "             'equal': 849,\n",
       "             'events': 850,\n",
       "             'fifth': 851,\n",
       "             'file': 852,\n",
       "             'films': 853,\n",
       "             'fox': 854,\n",
       "             'franklin': 855,\n",
       "             'free': 856,\n",
       "             'gate': 857,\n",
       "             'given': 858,\n",
       "             'going': 859,\n",
       "             'grow': 860,\n",
       "             'gulf': 861,\n",
       "             'harvey': 862,\n",
       "             'having': 863,\n",
       "             'himself': 864,\n",
       "             'hockey': 865,\n",
       "             'host': 866,\n",
       "             'inspired': 867,\n",
       "             'investigation': 868,\n",
       "             'iron': 869,\n",
       "             'italy': 870,\n",
       "             'jane': 871,\n",
       "             'jersey': 872,\n",
       "             'jewish': 873,\n",
       "             'johnny': 874,\n",
       "             'jude': 875,\n",
       "             'justice': 876,\n",
       "             'keep': 877,\n",
       "             'kids': 878,\n",
       "             'large': 879,\n",
       "             'leading': 880,\n",
       "             'leave': 881,\n",
       "             'lee': 882,\n",
       "             'literary': 883,\n",
       "             'madonna': 884,\n",
       "             'magic': 885,\n",
       "             'mary': 886,\n",
       "             'maurizio': 887,\n",
       "             'mccarren': 888,\n",
       "             'meant': 889,\n",
       "             'medicine': 890,\n",
       "             'members': 891,\n",
       "             'michael': 892,\n",
       "             'microsoft': 893,\n",
       "             'model': 894,\n",
       "             'mr.': 895,\n",
       "             'mrs.': 896,\n",
       "             'muppets': 897,\n",
       "             'murder': 898,\n",
       "             'mutombo': 899,\n",
       "             \"n't\": 900,\n",
       "             'nations': 901,\n",
       "             'native': 902,\n",
       "             'nfl': 903,\n",
       "             'occur': 904,\n",
       "             'order': 905,\n",
       "             'owns': 906,\n",
       "             'page': 907,\n",
       "             'painted': 908,\n",
       "             'painting': 909,\n",
       "             'pellegrin': 910,\n",
       "             'perfect': 911,\n",
       "             'period': 912,\n",
       "             'phone': 913,\n",
       "             'poem': 914,\n",
       "             'points': 915,\n",
       "             'pop': 916,\n",
       "             'presidential': 917,\n",
       "             'produces': 918,\n",
       "             'project': 919,\n",
       "             'read': 920,\n",
       "             'received': 921,\n",
       "             'reims': 922,\n",
       "             'religion': 923,\n",
       "             'remove': 924,\n",
       "             'represented': 925,\n",
       "             'research': 926,\n",
       "             'roosevelt': 927,\n",
       "             'salary': 928,\n",
       "             'same': 929,\n",
       "             'score': 930,\n",
       "             'seen': 931,\n",
       "             'serve': 932,\n",
       "             'sex': 933,\n",
       "             'silly': 934,\n",
       "             'silver': 935,\n",
       "             'simpsons': 936,\n",
       "             'single': 937,\n",
       "             'sister': 938,\n",
       "             'site': 939,\n",
       "             'sold': 940,\n",
       "             'spain': 941,\n",
       "             'spielberg': 942,\n",
       "             'submarine': 943,\n",
       "             'swimming': 944,\n",
       "             'tale': 945,\n",
       "             'taste': 946,\n",
       "             'temperature': 947,\n",
       "             'took': 948,\n",
       "             'treat': 949,\n",
       "             'turned': 950,\n",
       "             'twins': 951,\n",
       "             'universe': 952,\n",
       "             'usa': 953,\n",
       "             'using': 954,\n",
       "             'vegas': 955,\n",
       "             'vhs': 956,\n",
       "             'visit': 957,\n",
       "             'voice': 958,\n",
       "             'watergate': 959,\n",
       "             'ways': 960,\n",
       "             'wings': 961,\n",
       "             'working': 962,\n",
       "             'yankee': 963,\n",
       "             \"'ll\": 964,\n",
       "             '..': 965,\n",
       "             '000': 966,\n",
       "             '12': 967,\n",
       "             '13': 968,\n",
       "             '16th': 969,\n",
       "             '1939': 970,\n",
       "             '1960': 971,\n",
       "             '1965': 972,\n",
       "             '1967': 973,\n",
       "             '1969': 974,\n",
       "             '1980': 975,\n",
       "             '1994': 976,\n",
       "             '1998': 977,\n",
       "             '2000': 978,\n",
       "             'academy': 979,\n",
       "             'act': 980,\n",
       "             'ads': 981,\n",
       "             'adult': 982,\n",
       "             'advertise': 983,\n",
       "             'against': 984,\n",
       "             'ages': 985,\n",
       "             'ago': 986,\n",
       "             'airplane': 987,\n",
       "             'al': 988,\n",
       "             'along': 989,\n",
       "             'amendment': 990,\n",
       "             'appearance': 991,\n",
       "             'appeared': 992,\n",
       "             'arch': 993,\n",
       "             'arthur': 994,\n",
       "             'asia': 995,\n",
       "             'asked': 996,\n",
       "             'aspartame': 997,\n",
       "             'associated': 998,\n",
       "             'astronauts': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocab dictionaries\n",
    "text_field.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embeddings): Embedding(5002, 6)\n",
       "  (rnn): LSTM(6, 6, batch_first=True)\n",
       "  (linear): Linear(in_features=6, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_tokens, embedding_dim, rnn_dim, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_tokens, embedding_dim)\n",
    "        self.rnn = nn.LSTM(input_size = embedding_dim,\n",
    "                           hidden_size = rnn_dim, \n",
    "                           num_layers = num_layers,\n",
    "                           batch_first = True,\n",
    "                           bidirectional=False)\n",
    "        self.linear = nn.Linear(rnn_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embeddings(x)\n",
    "        rnn_output, rnn_hidden = self.rnn(emb) \n",
    "        x = rnn_output[:,-1,:]\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "model = RNN(word_count, 6, 6, 1, classes_count)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Objective function (and optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_decay = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train model (and test during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_iter = data.BucketIterator(train, \n",
    "                                 batch_size=batch_size, \n",
    "                                 sort_within_batch=True, \n",
    "                                 shuffle = True, \n",
    "                                 repeat = False)\n",
    "\n",
    "test_iter = data.BucketIterator(test, \n",
    "                          batch_size=30, \n",
    "                          sort_within_batch=True, \n",
    "                          shuffle = True, \n",
    "                          repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset variables \n",
    "accuracies = []\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "train_accuracy = 0\n",
    "step_count = 0\n",
    "max_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch  0\n",
      "Step:  0 Accuracy in test set: 0.2759999930858612\n",
      "Step:  100 Accuracy in test set: 0.2759999930858612\n",
      "Training epoch  1\n",
      "Step:  200 Accuracy in test set: 0.21400000154972076\n",
      "Step:  300 Accuracy in test set: 0.2980000078678131\n",
      "Training epoch  2\n",
      "Step:  400 Accuracy in test set: 0.32199999690055847\n",
      "Step:  500 Accuracy in test set: 0.3959999978542328\n",
      "Training epoch  3\n",
      "Step:  600 Accuracy in test set: 0.3779999911785126\n",
      "Training epoch  4\n",
      "Step:  700 Accuracy in test set: 0.3840000033378601\n",
      "Step:  800 Accuracy in test set: 0.4020000100135803\n",
      "Training epoch  5\n",
      "Step:  900 Accuracy in test set: 0.3880000114440918\n",
      "Step:  1000 Accuracy in test set: 0.3959999978542328\n",
      "Training epoch  6\n",
      "Step:  1100 Accuracy in test set: 0.4020000100135803\n",
      "Training epoch  7\n",
      "Step:  1200 Accuracy in test set: 0.3959999978542328\n",
      "Step:  1300 Accuracy in test set: 0.3959999978542328\n",
      "Training epoch  8\n",
      "Step:  1400 Accuracy in test set: 0.39399999380111694\n",
      "Step:  1500 Accuracy in test set: 0.3959999978542328\n",
      "Training epoch  9\n",
      "Step:  1600 Accuracy in test set: 0.39800000190734863\n",
      "Step:  1700 Accuracy in test set: 0.40799999237060547\n",
      "Training epoch  10\n",
      "Step:  1800 Accuracy in test set: 0.4020000100135803\n",
      "Training epoch  11\n",
      "Step:  1900 Accuracy in test set: 0.40400001406669617\n",
      "Step:  2000 Accuracy in test set: 0.40400001406669617\n",
      "Training epoch  12\n",
      "Step:  2100 Accuracy in test set: 0.40400001406669617\n",
      "Step:  2200 Accuracy in test set: 0.41600000858306885\n",
      "Training epoch  13\n",
      "Step:  2300 Accuracy in test set: 0.41200000047683716\n",
      "Training epoch  14\n",
      "Step:  2400 Accuracy in test set: 0.4059999883174896\n",
      "Step:  2500 Accuracy in test set: 0.4099999964237213\n",
      "Training epoch  15\n",
      "Step:  2600 Accuracy in test set: 0.40799999237060547\n",
      "Step:  2700 Accuracy in test set: 0.4059999883174896\n",
      "Training epoch  16\n",
      "Step:  2800 Accuracy in test set: 0.4099999964237213\n",
      "Step:  2900 Accuracy in test set: 0.40799999237060547\n",
      "Training epoch  17\n",
      "Step:  3000 Accuracy in test set: 0.4059999883174896\n",
      "Training epoch  18\n",
      "Step:  3100 Accuracy in test set: 0.414000004529953\n",
      "Step:  3200 Accuracy in test set: 0.4099999964237213\n",
      "Training epoch  19\n",
      "Step:  3300 Accuracy in test set: 0.40799999237060547\n",
      "Step:  3400 Accuracy in test set: 0.41200000047683716\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "for i in range(num_epochs):\n",
    "    print('Training epoch ',i)\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:        \n",
    "\n",
    "        x_train = batch.text\n",
    "        y_train = batch.label\n",
    "\n",
    "        # Forward pass\n",
    "        y_model = model(x_train)\n",
    "\n",
    "        # Loss function\n",
    "        loss = loss_function(y_model, y_train)\n",
    "        losses_train.append(float(loss))\n",
    "\n",
    "        # Backward pass \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluation in test set\n",
    "\n",
    "        if step_count%100 == 0:\n",
    "\n",
    "            # Calculate model in test set by pieces\n",
    "            model.eval() # Set model to eval (if there is dropout, will set it to zero)\n",
    "            y_model_test_list = []\n",
    "            y_test_list = []\n",
    "            \n",
    "            for test_batch in test_iter:            \n",
    "                y_model_test_list.append(model(test_batch.text))            \n",
    "                y_test_list.append(test_batch.label)\n",
    "            model.train() # Set model to train (if there is dropout, will not be zero anymore)\n",
    "            test_iter.init_epoch()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = float( (torch.cat(y_model_test_list).max(dim=1)[1] == torch.cat(y_test_list)).float().mean() )\n",
    "            print('Step: ', step_count, 'Accuracy in test set:', accuracy)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        lr_decay.step()\n",
    "        step_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcad4bd43c8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice: Improve your RNN \n",
    "\n",
    "Improve your recurrent network:\n",
    "* Apply dropout between the LSTM and the linear layer\n",
    "* Add more complexity to the model (RNN layers, other layers)\n",
    "* Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embeddings): Embedding(5002, 50)\n",
       "  (rnn): LSTM(50, 20, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear): Linear(in_features=40, out_features=20, bias=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (linear2): Linear(in_features=20, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_tokens, embedding_dim, rnn_dim, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_tokens, embedding_dim)\n",
    "        self.rnn = nn.LSTM(input_size = embedding_dim,\n",
    "                           hidden_size = rnn_dim, \n",
    "                           num_layers = num_layers,\n",
    "                           batch_first = True,\n",
    "                           bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(2*rnn_dim, rnn_dim)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.linear2 = nn.Linear(rnn_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embeddings(x)\n",
    "        rnn_output, rnn_hidden = self.rnn(emb) \n",
    "        x = self.dropout(rnn_output)\n",
    "        x = self.linear(rnn_output[:,-1,:])\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = RNN(word_count, 50, 20, 3, classes_count)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_decay = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_iter = data.BucketIterator(train, \n",
    "                                 batch_size=batch_size, \n",
    "                                 sort_within_batch=True, \n",
    "                                 shuffle = True, \n",
    "                                 repeat = False)\n",
    "\n",
    "test_iter = data.BucketIterator(test, \n",
    "                          batch_size=30, \n",
    "                          sort_within_batch=True, \n",
    "                          shuffle = True, \n",
    "                          repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset variables \n",
    "accuracies = []\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "train_accuracy = 0\n",
    "step_count = 0\n",
    "max_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch  0\n",
      "Step:  0 Accuracy in test set: 0.12999999523162842\n",
      "Step:  100 Accuracy in test set: 0.38199999928474426\n",
      "Training epoch  1\n",
      "Step:  200 Accuracy in test set: 0.5320000052452087\n",
      "Step:  300 Accuracy in test set: 0.5839999914169312\n",
      "Training epoch  2\n",
      "Step:  400 Accuracy in test set: 0.6079999804496765\n",
      "Step:  500 Accuracy in test set: 0.6119999885559082\n",
      "Training epoch  3\n",
      "Step:  600 Accuracy in test set: 0.628000020980835\n",
      "Training epoch  4\n",
      "Step:  700 Accuracy in test set: 0.6259999871253967\n",
      "Step:  800 Accuracy in test set: 0.6700000166893005\n",
      "Training epoch  5\n",
      "Step:  900 Accuracy in test set: 0.6660000085830688\n",
      "Step:  1000 Accuracy in test set: 0.6660000085830688\n",
      "Training epoch  6\n",
      "Step:  1100 Accuracy in test set: 0.671999990940094\n",
      "Training epoch  7\n",
      "Step:  1200 Accuracy in test set: 0.6779999732971191\n",
      "Step:  1300 Accuracy in test set: 0.6740000247955322\n",
      "Training epoch  8\n",
      "Step:  1400 Accuracy in test set: 0.6819999814033508\n",
      "Step:  1500 Accuracy in test set: 0.6940000057220459\n",
      "Training epoch  9\n",
      "Step:  1600 Accuracy in test set: 0.6800000071525574\n",
      "Step:  1700 Accuracy in test set: 0.6880000233650208\n",
      "Training epoch  10\n",
      "Step:  1800 Accuracy in test set: 0.6819999814033508\n",
      "Training epoch  11\n",
      "Step:  1900 Accuracy in test set: 0.7059999704360962\n",
      "Step:  2000 Accuracy in test set: 0.7039999961853027\n",
      "Training epoch  12\n",
      "Step:  2100 Accuracy in test set: 0.6919999718666077\n",
      "Step:  2200 Accuracy in test set: 0.7160000205039978\n",
      "Training epoch  13\n",
      "Step:  2300 Accuracy in test set: 0.7099999785423279\n",
      "Training epoch  14\n",
      "Step:  2400 Accuracy in test set: 0.7179999947547913\n",
      "Step:  2500 Accuracy in test set: 0.7179999947547913\n",
      "Training epoch  15\n",
      "Step:  2600 Accuracy in test set: 0.722000002861023\n",
      "Step:  2700 Accuracy in test set: 0.7319999933242798\n",
      "Training epoch  16\n",
      "Step:  2800 Accuracy in test set: 0.7319999933242798\n",
      "Step:  2900 Accuracy in test set: 0.7239999771118164\n",
      "Training epoch  17\n",
      "Step:  3000 Accuracy in test set: 0.734000027179718\n",
      "Training epoch  18\n",
      "Step:  3100 Accuracy in test set: 0.7379999756813049\n",
      "Step:  3200 Accuracy in test set: 0.734000027179718\n",
      "Training epoch  19\n",
      "Step:  3300 Accuracy in test set: 0.7459999918937683\n",
      "Step:  3400 Accuracy in test set: 0.7379999756813049\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for i in range(num_epochs):\n",
    "    print('Training epoch ',i)\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:        \n",
    "\n",
    "        x_train = batch.text\n",
    "        y_train = batch.label\n",
    "\n",
    "        # Forward pass\n",
    "        y_model = model(x_train)\n",
    "\n",
    "        # Loss function\n",
    "        loss = loss_function(y_model, y_train)\n",
    "        losses_train.append(float(loss))\n",
    "\n",
    "        # Backward pass \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluation in test set\n",
    "\n",
    "        if step_count%100 == 0:\n",
    "\n",
    "            # Calculate model in test set by pieces\n",
    "            model.eval() # Set model to eval (if there is dropout, will set it to zero)\n",
    "            y_model_test_list = []\n",
    "            y_test_list = []\n",
    "            \n",
    "            for test_batch in test_iter:            \n",
    "                y_model_test_list.append(model(test_batch.text))            \n",
    "                y_test_list.append(test_batch.label)\n",
    "            model.train() # Set model to train (if there is dropout, will not be zero anymore)\n",
    "            test_iter.init_epoch()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = float( (torch.cat(y_model_test_list).max(dim=1)[1] == torch.cat(y_test_list)).float().mean() )\n",
    "            print('Step: ', step_count, 'Accuracy in test set:', accuracy)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        lr_decay.step()\n",
    "        step_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
